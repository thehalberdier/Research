[
  {
    "objectID": "rust_primer.html",
    "href": "rust_primer.html",
    "title": "Rust Primer for C++/Java Developers",
    "section": "",
    "text": "Goal: Get you to ~80% of Rust, fast. Assumes you know C++/Java, understand types, pointers, and memory. Skips: async runtime internals, FFI, advanced lifetime gymnastics."
  },
  {
    "objectID": "rust_primer.html#first-things-first-cargo-project-setup",
    "href": "rust_primer.html#first-things-first-cargo-project-setup",
    "title": "Rust Primer for C++/Java Developers",
    "section": "1. First Things First: Cargo & Project Setup",
    "text": "1. First Things First: Cargo & Project Setup\nCargo is Rust‚Äôs build system + package manager. Think CMake + Conan + Maven rolled into one, but actually pleasant.\ncargo new myproject        # creates a new binary project\ncargo new mylib --lib      # creates a library\ncargo build                # compile (debug)\ncargo build --release      # compile (optimized)\ncargo run                  # build + run\ncargo test                 # run tests\ncargo add serde            # add a dependency (like `npm install`)\nProject structure:\nmyproject/\n‚îú‚îÄ‚îÄ Cargo.toml             # like pom.xml / CMakeLists.txt\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îî‚îÄ‚îÄ main.rs            # entry point (fn main)\nCargo.toml declares dependencies:\n[dependencies]\nserde = { version = \"1.0\", features = [\"derive\"] }\ntokio = { version = \"1\", features = [\"full\"] }\nCrates.io is the package registry (like Maven Central / crates ‚âà packages)."
  },
  {
    "objectID": "rust_primer.html#the-big-idea-ownership",
    "href": "rust_primer.html#the-big-idea-ownership",
    "title": "Rust Primer for C++/Java Developers",
    "section": "2. The Big Idea: Ownership",
    "text": "2. The Big Idea: Ownership\nThis is THE thing that makes Rust different. If you internalize this section, the rest falls into place.\n\nThe Three Rules\n\nEvery value has exactly one owner (a variable).\nWhen the owner goes out of scope, the value is dropped (destructor runs, memory freed).\nOwnership can be moved, but then the old variable is invalid.\n\nfn main() {\n    let s1 = String::from(\"hello\");  // s1 owns the String\n    let s2 = s1;                      // ownership MOVED to s2\n    // println!(\"{}\", s1);            // COMPILE ERROR: s1 is no longer valid\n    println!(\"{}\", s2);               // fine\n}\nC++ analogy: Think std::unique_ptr. Assignment = move. But Rust enforces this for ALL types at compile time, not just smart pointers.\nJava comparison: In Java, s2 = s1 makes both point to the same object. In Rust, s1 is dead after the move.\n\n\nStack vs.¬†Heap & Copy Types\nSimple scalar types (i32, f64, bool, char, tuples of these) implement Copy ‚Äî they‚Äôre copied on assignment, not moved. Just like in C++.\nlet x = 5;\nlet y = x;       // x is copied, both valid\nprintln!(\"{x} {y}\"); // fine\nHeap-allocated types (String, Vec&lt;T&gt;, Box&lt;T&gt;) are moved.\n\n\nClone: Explicit Deep Copy\nIf you actually want a deep copy, say so:\nlet s1 = String::from(\"hello\");\nlet s2 = s1.clone();  // explicit deep copy\nprintln!(\"{s1} {s2}\"); // both valid"
  },
  {
    "objectID": "rust_primer.html#borrowing-references",
    "href": "rust_primer.html#borrowing-references",
    "title": "Rust Primer for C++/Java Developers",
    "section": "3. Borrowing & References",
    "text": "3. Borrowing & References\nYou don‚Äôt always want to move ownership. Borrowing lets you lend access.\nfn print_length(s: &String) {   // borrows s (immutable reference)\n    println!(\"len = {}\", s.len());\n}\n\nfn main() {\n    let s = String::from(\"hello\");\n    print_length(&s);            // lend s\n    println!(\"{s}\");             // still valid ‚Äî we only lent it\n}\n\nThe Borrowing Rules\nAt any given time, you can have either: - Any number of immutable references (&T), OR - Exactly one mutable reference (&mut T)\nNever both at the same time.\nlet mut s = String::from(\"hello\");\n\nlet r1 = &s;       // ok\nlet r2 = &s;       // ok ‚Äî multiple immutable refs fine\n// let r3 = &mut s; // COMPILE ERROR: can't borrow mutably while immutable refs exist\n\nprintln!(\"{r1} {r2}\");\n// r1, r2 no longer used after this point (their lifetime ends)\n\nlet r3 = &mut s;   // now ok ‚Äî no immutable refs alive\nr3.push_str(\" world\");\nWhy: This is Rust‚Äôs compile-time data race prevention. No reader-writer conflicts, ever.\nC++ analogy: Like const T& vs T&, but the compiler actually enforces that you can‚Äôt alias a mutable ref."
  },
  {
    "objectID": "rust_primer.html#lifetimes-the-minimum-you-need",
    "href": "rust_primer.html#lifetimes-the-minimum-you-need",
    "title": "Rust Primer for C++/Java Developers",
    "section": "4. Lifetimes (The Minimum You Need)",
    "text": "4. Lifetimes (The Minimum You Need)\nLifetimes ensure references don‚Äôt outlive the data they point to. Most of the time, the compiler infers them. You only write them when the compiler can‚Äôt figure it out ‚Äî typically in function signatures returning references.\n// \"The returned reference lives as long as BOTH inputs live\"\nfn longer&lt;'a&gt;(s1: &'a str, s2: &'a str) -&gt; &'a str {\n    if s1.len() &gt;= s2.len() { s1 } else { s2 }\n}\n'a is a lifetime parameter. Read it as: ‚Äúthe output reference is valid for at least as long as both input references.‚Äù\nPractical rule of thumb: If the compiler says ‚Äúmissing lifetime specifier,‚Äù add &lt;'a&gt; to the function and annotate the references. If you‚Äôre storing references in a struct, you need lifetimes on the struct too:\nstruct Excerpt&lt;'a&gt; {\n    text: &'a str,   // this struct can't outlive the string it borrows\n}\nEscape hatch: If lifetimes get painful, just own the data instead (String instead of &str, Vec&lt;T&gt; instead of &[T]). Cloning is fine. Don‚Äôt fight the borrow checker when you‚Äôre learning."
  },
  {
    "objectID": "rust_primer.html#types-structs-enums",
    "href": "rust_primer.html#types-structs-enums",
    "title": "Rust Primer for C++/Java Developers",
    "section": "5. Types, Structs, Enums",
    "text": "5. Types, Structs, Enums\n\nPrimitive Types\nlet x: i32 = 42;        // signed: i8, i16, i32, i64, i128, isize\nlet y: u64 = 100;       // unsigned: u8, u16, u32, u64, u128, usize\nlet f: f64 = 3.14;      // f32, f64\nlet b: bool = true;\nlet c: char = 'ü¶Ä';     // 4 bytes, Unicode scalar value\nusize / isize = pointer-sized integers. Used for indexing.\n\n\nStructs (like C++ structs / Java classes, but no inheritance)\nstruct Server {\n    hostname: String,\n    cpu_cores: u32,\n    is_active: bool,\n}\n\nimpl Server {\n    // Associated function (like static method). Convention: `new` is the constructor.\n    fn new(hostname: String, cores: u32) -&gt; Self {\n        Server {\n            hostname,          // shorthand when field name == variable name\n            cpu_cores: cores,\n            is_active: true,\n        }\n    }\n\n    // Method: takes &self (immutable borrow of the instance)\n    fn summary(&self) -&gt; String {\n        format!(\"{}: {} cores\", self.hostname, self.cpu_cores)\n    }\n\n    // Mutable method: takes &mut self\n    fn deactivate(&mut self) {\n        self.is_active = false;\n    }\n}\n\nfn main() {\n    let mut srv = Server::new(\"node-01\".to_string(), 64);\n    println!(\"{}\", srv.summary());\n    srv.deactivate();\n}\nNo inheritance. Composition + traits instead (see ¬ß7).\n\n\nEnums (WAY more powerful than C++/Java enums)\nRust enums are algebraic data types (tagged unions). Each variant can hold data.\nenum StorageBackend {\n    Local { path: String },\n    Ceph { pool: String, namespace: String },\n    NVMe { device_id: u32 },\n    None,\n}\n\nfn describe(backend: &StorageBackend) {\n    match backend {\n        StorageBackend::Local { path } =&gt; println!(\"Local at {path}\"),\n        StorageBackend::Ceph { pool, .. } =&gt; println!(\"Ceph pool: {pool}\"),\n        StorageBackend::NVMe { device_id } =&gt; println!(\"NVMe dev {device_id}\"),\n        StorageBackend::None =&gt; println!(\"No storage\"),\n    }\n}\nC++ analogy: std::variant, but with exhaustive pattern matching enforced by the compiler."
  },
  {
    "objectID": "rust_primer.html#pattern-matching",
    "href": "rust_primer.html#pattern-matching",
    "title": "Rust Primer for C++/Java Developers",
    "section": "6. Pattern Matching",
    "text": "6. Pattern Matching\nmatch is like switch on steroids. It‚Äôs exhaustive ‚Äî you must handle every case.\nlet x = 42;\n\nmatch x {\n    0 =&gt; println!(\"zero\"),\n    1..=10 =&gt; println!(\"small\"),\n    11 | 12 =&gt; println!(\"eleven or twelve\"),\n    n if n &lt; 0 =&gt; println!(\"negative: {n}\"),   // guard\n    _ =&gt; println!(\"something else\"),             // _ = default\n}\n\nif let ‚Äî when you only care about one variant\nlet maybe_name: Option&lt;String&gt; = Some(\"venkat\".to_string());\n\nif let Some(name) = maybe_name {\n    println!(\"Got: {name}\");\n}\n// Use this instead of a full match when you don't care about the other cases.\n\n\nlet ... else ‚Äî early return on mismatch (Rust 1.65+)\nfn process(val: Option&lt;i32&gt;) {\n    let Some(x) = val else {\n        println!(\"was None, bailing\");\n        return;\n    };\n    println!(\"processing {x}\");\n}"
  },
  {
    "objectID": "rust_primer.html#traits-interfaces-typeclasses",
    "href": "rust_primer.html#traits-interfaces-typeclasses",
    "title": "Rust Primer for C++/Java Developers",
    "section": "7. Traits (‚âà Interfaces + Typeclasses)",
    "text": "7. Traits (‚âà Interfaces + Typeclasses)\nTraits define shared behavior. Like Java interfaces, but can have default implementations and can be implemented for types you didn‚Äôt define.\ntrait Describable {\n    fn describe(&self) -&gt; String;\n\n    // Default implementation (like Java default methods)\n    fn short_desc(&self) -&gt; String {\n        format!(\"{}...\", &self.describe()[..20.min(self.describe().len())])\n    }\n}\n\nimpl Describable for Server {\n    fn describe(&self) -&gt; String {\n        format!(\"Server {} with {} cores\", self.hostname, self.cpu_cores)\n    }\n}\n\nTrait Bounds (= Generics constrained by traits)\n// Any T that implements Describable\nfn log_item&lt;T: Describable&gt;(item: &T) {\n    println!(\"[LOG] {}\", item.describe());\n}\n\n// Equivalent with `where` clause (cleaner for multiple bounds)\nfn log_item2&lt;T&gt;(item: &T)\nwhere\n    T: Describable + Clone + std::fmt::Debug,\n{\n    println!(\"[LOG] {:?} ‚Äî {}\", item, item.describe());\n}\n\n\nimpl Trait syntax (simpler)\nfn log_item3(item: &impl Describable) {  // same as the generic version above\n    println!(\"[LOG] {}\", item.describe());\n}\n\nfn make_server() -&gt; impl Describable {    // return \"some type that is Describable\"\n    Server::new(\"anon\".into(), 8)\n}\n\n\nCommon Standard Library Traits You‚Äôll Use Constantly\n\n\n\nTrait\nWhat it does\nC++/Java analogy\n\n\n\n\nClone\nExplicit deep copy (.clone())\nCopy constructor\n\n\nCopy\nImplicit bitwise copy\nPOD types\n\n\nDebug\nFormat with {:?} for debugging\ntoString() for debug\n\n\nDisplay\nFormat with {} for user-facing output\ntoString()\n\n\nPartialEq, Eq\n== / !=\noperator== / equals()\n\n\nPartialOrd, Ord\n&lt;, &gt;, sorting\noperator&lt; / Comparable\n\n\nHash\nHashing for HashMap keys\nhashCode()\n\n\nDefault\nDefault value (T::default())\nDefault constructor\n\n\nFrom / Into\nType conversion\nConversion constructors\n\n\nIterator\nIteration protocol\nIterator&lt;T&gt;\n\n\nDrop\nDestructor\nDestructor / finalize()\n\n\n\nMost of these can be auto-derived:\n#[derive(Debug, Clone, PartialEq, Eq, Hash)]\nstruct NodeId {\n    rack: u32,\n    slot: u32,\n}"
  },
  {
    "objectID": "rust_primer.html#error-handling-result-and-option",
    "href": "rust_primer.html#error-handling-result-and-option",
    "title": "Rust Primer for C++/Java Developers",
    "section": "8. Error Handling: Result and Option",
    "text": "8. Error Handling: Result and Option\nNo exceptions in Rust. Errors are values.\n\nOption&lt;T&gt; ‚Äî value might be absent\n// Option is just: enum Option&lt;T&gt; { Some(T), None }\n\nfn find_server(id: u32) -&gt; Option&lt;Server&gt; {\n    if id == 1 {\n        Some(Server::new(\"node-01\".into(), 64))\n    } else {\n        None\n    }\n}\n\n// Handling:\nmatch find_server(1) {\n    Some(srv) =&gt; println!(\"{}\", srv.summary()),\n    None =&gt; println!(\"not found\"),\n}\n\n// Or more concisely:\nlet srv = find_server(1).unwrap();             // panics if None (like .get() on null)\nlet srv = find_server(1).unwrap_or(default);   // fallback\nlet srv = find_server(1).expect(\"server 1 must exist\"); // panic with message\n\n\nResult&lt;T, E&gt; ‚Äî operation might fail\n// Result is just: enum Result&lt;T, E&gt; { Ok(T), Err(E) }\n\nuse std::fs;\nuse std::io;\n\nfn read_config(path: &str) -&gt; Result&lt;String, io::Error&gt; {\n    fs::read_to_string(path)\n}\n\nfn main() {\n    match read_config(\"/etc/myapp.conf\") {\n        Ok(contents) =&gt; println!(\"Config: {contents}\"),\n        Err(e) =&gt; eprintln!(\"Failed: {e}\"),\n    }\n}\n\n\nThe ? Operator (This Is Huge)\n? propagates errors upward. If the Result is Err, return early with that error. If Ok, unwrap the value. This replaces try-catch with zero boilerplate.\nfn load_and_parse_config(path: &str) -&gt; Result&lt;Config, Box&lt;dyn std::error::Error&gt;&gt; {\n    let contents = fs::read_to_string(path)?;   // returns Err early if file read fails\n    let config: Config = serde_json::from_str(&contents)?;  // returns Err if parse fails\n    Ok(config)\n}\nC++ analogy: Like if every function returned std::expected&lt;T, E&gt; and you had a concise syntax for early returns.\nPractical advice: Use anyhow::Result (from the anyhow crate) for applications and thiserror for libraries.\n// In Cargo.toml: anyhow = \"1\"\nuse anyhow::{Context, Result};\n\nfn load_config(path: &str) -&gt; Result&lt;Config&gt; {\n    let contents = fs::read_to_string(path)\n        .context(\"failed to read config file\")?;    // adds context to error\n    let config = serde_json::from_str(&contents)\n        .context(\"failed to parse config\")?;\n    Ok(config)\n}"
  },
  {
    "objectID": "rust_primer.html#collections-iterators",
    "href": "rust_primer.html#collections-iterators",
    "title": "Rust Primer for C++/Java Developers",
    "section": "9. Collections & Iterators",
    "text": "9. Collections & Iterators\n\nKey Collections\nuse std::collections::HashMap;\n\n// Vec&lt;T&gt; ‚Äî dynamic array (like std::vector / ArrayList)\nlet mut nums: Vec&lt;i32&gt; = vec![1, 2, 3];\nnums.push(4);\n\n// String ‚Äî owned, growable UTF-8 string\nlet mut s = String::from(\"hello\");\ns.push_str(\" world\");\n\n// &str ‚Äî string slice (borrowed view into a String or literal)\nlet slice: &str = &s[0..5];\n\n// HashMap&lt;K, V&gt; ‚Äî hash map (like std::unordered_map / HashMap)\nlet mut scores: HashMap&lt;String, i32&gt; = HashMap::new();\nscores.insert(\"node-01\".into(), 95);\n\n// VecDeque, BTreeMap, BTreeSet, HashSet also available\n\n\nIterators (Rust‚Äôs Secret Weapon)\nRust iterators are lazy, zero-cost abstractions. They compile down to the same code as hand-written loops.\nlet nums = vec![1, 2, 3, 4, 5, 6, 7, 8, 9, 10];\n\n// Chained iterator operations\nlet result: Vec&lt;i32&gt; = nums.iter()\n    .filter(|&&x| x % 2 == 0)       // keep evens\n    .map(|&x| x * x)                // square them\n    .collect();                       // collect into Vec\n// result = [4, 16, 36, 64, 100]\n\n// Sum\nlet total: i32 = nums.iter().sum();\n\n// Find\nlet first_big = nums.iter().find(|&&x| x &gt; 5);  // Option&lt;&i32&gt;\n\n// for loop (uses IntoIterator under the hood)\nfor num in &nums {\n    println!(\"{num}\");\n}\n\n// Enumerate (like Python)\nfor (i, num) in nums.iter().enumerate() {\n    println!(\"[{i}] = {num}\");\n}\n\n// Iterating over HashMap\nfor (key, value) in &scores {\n    println!(\"{key}: {value}\");\n}\nKey iterator methods: map, filter, flat_map, fold, reduce, take, skip, zip, enumerate, any, all, find, position, collect, count, sum, min, max, chain, peekable.\n.collect() can produce different collection types based on the type annotation ‚Äî it‚Äôs generic over the output type."
  },
  {
    "objectID": "rust_primer.html#closures",
    "href": "rust_primer.html#closures",
    "title": "Rust Primer for C++/Java Developers",
    "section": "10. Closures",
    "text": "10. Closures\n// Type-inferred closure\nlet add = |a, b| a + b;\nprintln!(\"{}\", add(2, 3));\n\n// With explicit types\nlet square = |x: i32| -&gt; i32 { x * x };\n\n// Closures capture variables from their environment\nlet threshold = 50;\nlet above_threshold = |x: &i32| *x &gt; threshold;    // borrows `threshold`\n\nlet results: Vec&lt;&i32&gt; = nums.iter().filter(|x| above_threshold(x)).collect();\n\n// Move closure ‚Äî takes ownership of captured variables\nlet name = String::from(\"venkat\");\nlet greeting = move || println!(\"Hello, {name}\");    // `name` moved into closure\n// `name` is no longer usable here\ngreeting();\nClosures implement one or more of: Fn (borrows immutably), FnMut (borrows mutably), FnOnce (takes ownership). The compiler figures this out."
  },
  {
    "objectID": "rust_primer.html#smart-pointers",
    "href": "rust_primer.html#smart-pointers",
    "title": "Rust Primer for C++/Java Developers",
    "section": "11. Smart Pointers",
    "text": "11. Smart Pointers\n\n\n\n\n\n\n\n\nType\nWhat it does\nC++ analogy\n\n\n\n\nBox&lt;T&gt;\nHeap allocation, single owner\nstd::unique_ptr&lt;T&gt;\n\n\nRc&lt;T&gt;\nReference-counted, single thread\nstd::shared_ptr&lt;T&gt;\n\n\nArc&lt;T&gt;\nReference-counted, thread-safe\nstd::shared_ptr&lt;T&gt; (atomic)\n\n\nRefCell&lt;T&gt;\nInterior mutability (runtime borrow checks)\n‚Äî\n\n\nMutex&lt;T&gt;\nMutual exclusion with owned data\nstd::mutex + the data it protects\n\n\nRwLock&lt;T&gt;\nReader-writer lock with owned data\nstd::shared_mutex + data\n\n\n\n// Box: heap allocation\nlet boxed: Box&lt;i32&gt; = Box::new(42);\n\n// Arc + Mutex: shared mutable state across threads\nuse std::sync::{Arc, Mutex};\n\nlet counter = Arc::new(Mutex::new(0));\nlet counter_clone = Arc::clone(&counter);\n\nstd::thread::spawn(move || {\n    let mut num = counter_clone.lock().unwrap();\n    *num += 1;\n});\nKey insight: In Rust, Mutex&lt;T&gt; owns the data it protects. You can‚Äôt access the data without locking. This makes data races structurally impossible."
  },
  {
    "objectID": "rust_primer.html#concurrency",
    "href": "rust_primer.html#concurrency",
    "title": "Rust Primer for C++/Java Developers",
    "section": "12. Concurrency",
    "text": "12. Concurrency\n\nThreads\nuse std::thread;\n\nlet handle = thread::spawn(|| {\n    println!(\"hello from thread\");\n    42   // return value\n});\n\nlet result = handle.join().unwrap();  // wait + get result\n\n\nChannels (message passing)\nuse std::sync::mpsc;  // multi-producer, single-consumer\n\nlet (tx, rx) = mpsc::channel();\nlet tx2 = tx.clone();   // clone sender for multiple producers\n\nthread::spawn(move || { tx.send(\"from thread 1\").unwrap(); });\nthread::spawn(move || { tx2.send(\"from thread 2\").unwrap(); });\n\nfor msg in rx {  // blocks until all senders dropped\n    println!(\"Got: {msg}\");\n}\n\n\nAsync/Await (brief overview)\nRust has async syntax but no built-in runtime. You pick one (usually tokio).\n// Cargo.toml: tokio = { version = \"1\", features = [\"full\"] }\n\n#[tokio::main]\nasync fn main() {\n    let result = fetch_data().await;\n    println!(\"{result}\");\n}\n\nasync fn fetch_data() -&gt; String {\n    // async operations here\n    \"data\".to_string()\n}"
  },
  {
    "objectID": "rust_primer.html#modules-visibility",
    "href": "rust_primer.html#modules-visibility",
    "title": "Rust Primer for C++/Java Developers",
    "section": "13. Modules & Visibility",
    "text": "13. Modules & Visibility\n// In src/main.rs or src/lib.rs\n\nmod network {                    // inline module\n    pub struct Connection {      // pub = public\n        pub host: String,\n        port: u16,               // private by default\n    }\n\n    impl Connection {\n        pub fn new(host: String, port: u16) -&gt; Self {\n            Connection { host, port }\n        }\n\n        pub fn connect(&self) {\n            println!(\"Connecting to {}:{}\", self.host, self.port);\n        }\n    }\n\n    pub mod dns {                // nested module\n        pub fn resolve(hostname: &str) -&gt; String {\n            format!(\"192.168.1.1 (resolved {hostname})\")\n        }\n    }\n}\n\nfn main() {\n    let conn = network::Connection::new(\"10.0.0.1\".into(), 8080);\n    conn.connect();\n    let ip = network::dns::resolve(\"node-01\");\n}\nFor file-based modules:\nsrc/\n‚îú‚îÄ‚îÄ main.rs         // declares: mod network;\n‚îú‚îÄ‚îÄ network/\n‚îÇ   ‚îú‚îÄ‚îÄ mod.rs      // declares: pub mod dns;\n‚îÇ   ‚îî‚îÄ‚îÄ dns.rs      // the dns module\nOr the newer flat style (Rust 2018+):\nsrc/\n‚îú‚îÄ‚îÄ main.rs         // declares: mod network;\n‚îú‚îÄ‚îÄ network.rs      // the network module, declares: pub mod dns;\n‚îú‚îÄ‚îÄ network/\n‚îÇ   ‚îî‚îÄ‚îÄ dns.rs\nuse brings items into scope:\nuse network::Connection;\nuse std::collections::HashMap;\nuse std::io::{self, Read, Write};  // multiple imports"
  },
  {
    "objectID": "rust_primer.html#generics",
    "href": "rust_primer.html#generics",
    "title": "Rust Primer for C++/Java Developers",
    "section": "14. Generics",
    "text": "14. Generics\nLike C++ templates / Java generics, but with trait bounds instead of SFINAE / concepts.\n// Generic function\nfn largest&lt;T: PartialOrd&gt;(list: &[T]) -&gt; &T {\n    let mut largest = &list[0];\n    for item in &list[1..] {\n        if item &gt; largest {\n            largest = item;\n        }\n    }\n    largest\n}\n\n// Generic struct\nstruct Cache&lt;K, V&gt; {\n    entries: HashMap&lt;K, V&gt;,\n    max_size: usize,\n}\n\nimpl&lt;K: Eq + Hash, V&gt; Cache&lt;K, V&gt; {\n    fn new(max_size: usize) -&gt; Self {\n        Cache {\n            entries: HashMap::new(),\n            max_size,\n        }\n    }\n\n    fn get(&self, key: &K) -&gt; Option&lt;&V&gt; {\n        self.entries.get(key)\n    }\n}\n\nDynamic Dispatch (dyn Trait)\nWhen you need runtime polymorphism (like virtual functions in C++ / interface references in Java):\nfn log_all(items: &[&dyn Describable]) {\n    for item in items {\n        println!(\"{}\", item.describe());\n    }\n}\n\n// Or with Box for owned trait objects\nfn get_backend(config: &str) -&gt; Box&lt;dyn StorageTrait&gt; {\n    match config {\n        \"ceph\" =&gt; Box::new(CephBackend::new()),\n        \"local\" =&gt; Box::new(LocalBackend::new()),\n        _ =&gt; panic!(\"unknown backend\"),\n    }\n}\ndyn Trait = vtable dispatch (like C++ virtual). impl Trait / generics = monomorphization (like C++ templates). Prefer generics for performance; use dyn when you need heterogeneous collections or runtime selection."
  },
  {
    "objectID": "rust_primer.html#string-types-cheat-sheet",
    "href": "rust_primer.html#string-types-cheat-sheet",
    "title": "Rust Primer for C++/Java Developers",
    "section": "15. String Types Cheat Sheet",
    "text": "15. String Types Cheat Sheet\nThis trips up every newcomer:\n\n\n\n\n\n\n\n\nType\nWhat\nAnalogy\n\n\n\n\nString\nOwned, heap-allocated, growable\nstd::string\n\n\n&str\nBorrowed slice (view into a String or literal)\nstd::string_view / const char*\n\n\n\nlet owned: String = String::from(\"hello\");   // or \"hello\".to_string()\nlet slice: &str = &owned;                     // borrow as slice\nlet literal: &str = \"hello\";                  // string literal (lives in binary, static lifetime)\n\n// Convert between them:\nlet s: String = \"hello\".to_string();          // &str ‚Üí String\nlet s: String = String::from(\"hello\");        // same\nlet s: &str = &owned;                         // String ‚Üí &str (via Deref coercion)\nlet s: &str = owned.as_str();                 // explicit\nRule of thumb: Functions should take &str as input (accepts both) and return String if they‚Äôre creating new string data."
  },
  {
    "objectID": "rust_primer.html#testing",
    "href": "rust_primer.html#testing",
    "title": "Rust Primer for C++/Java Developers",
    "section": "16. Testing",
    "text": "16. Testing\nTests live right next to the code. No separate test files needed (though you can have them).\npub fn add(a: i32, b: i32) -&gt; i32 {\n    a + b\n}\n\n#[cfg(test)]                       // only compiled during `cargo test`\nmod tests {\n    use super::*;                  // import from parent module\n\n    #[test]\n    fn test_add() {\n        assert_eq!(add(2, 3), 5);\n    }\n\n    #[test]\n    fn test_add_negative() {\n        assert_eq!(add(-1, 1), 0);\n    }\n\n    #[test]\n    #[should_panic(expected = \"overflow\")]\n    fn test_overflow() {\n        // test that something panics\n    }\n}\nIntegration tests go in tests/ directory at the project root."
  },
  {
    "objectID": "rust_primer.html#practical-patterns-youll-use-daily",
    "href": "rust_primer.html#practical-patterns-youll-use-daily",
    "title": "Rust Primer for C++/Java Developers",
    "section": "17. Practical Patterns You‚Äôll Use Daily",
    "text": "17. Practical Patterns You‚Äôll Use Daily\n\nBuilder Pattern (common in Rust APIs)\nlet client = ClientBuilder::new()\n    .timeout(Duration::from_secs(30))\n    .max_retries(3)\n    .base_url(\"https://api.example.com\")\n    .build()?;\n\n\nFrom / Into Conversions\nimpl From&lt;NodeConfig&gt; for Server {\n    fn from(config: NodeConfig) -&gt; Self {\n        Server::new(config.hostname, config.cores)\n    }\n}\n\n// Now you can do:\nlet server: Server = config.into();\nlet server = Server::from(config);\n\n\nType Aliases\ntype Result&lt;T&gt; = std::result::Result&lt;T, MyError&gt;;   // common in libraries\ntype NodeMap = HashMap&lt;String, Vec&lt;Server&gt;&gt;;\n\n\nDestructuring\nlet (x, y, z) = (1, 2, 3);\n\nlet Server { hostname, cpu_cores, .. } = &server;   // struct destructuring\n\nif let Ok(config) = load_config(\"path\") {\n    // use config\n}"
  },
  {
    "objectID": "rust_primer.html#key-differences-cheat-sheet",
    "href": "rust_primer.html#key-differences-cheat-sheet",
    "title": "Rust Primer for C++/Java Developers",
    "section": "18. Key Differences Cheat Sheet",
    "text": "18. Key Differences Cheat Sheet\n\n\n\n\n\n\n\n\n\nConcept\nC++\nJava\nRust\n\n\n\n\nMemory\nManual / RAII\nGC\nOwnership + RAII\n\n\nNull\nnullptr\nnull\nOption&lt;T&gt; (no null)\n\n\nErrors\nExceptions / error codes\nExceptions\nResult&lt;T, E&gt;\n\n\nInheritance\nClass hierarchy\nClass hierarchy\nNone (use traits + composition)\n\n\nPolymorphism\nVirtual functions\nInterfaces\nTraits (dyn or generics)\n\n\nConcurrency safety\n‚Äúbe careful‚Äù\n‚Äúbe careful‚Äù\nCompile-time enforcement\n\n\nPackage manager\n???\nMaven/Gradle\nCargo (it‚Äôs great)\n\n\nStrings\nstd::string / const char*\nString\nString / &str\n\n\nDefault mutability\nMutable\nMutable (refs)\nImmutable"
  },
  {
    "objectID": "rust_primer.html#quick-syntax-reference",
    "href": "rust_primer.html#quick-syntax-reference",
    "title": "Rust Primer for C++/Java Developers",
    "section": "19. Quick Syntax Reference",
    "text": "19. Quick Syntax Reference\n// Variables\nlet x = 5;                     // immutable\nlet mut y = 10;                // mutable\nlet z: i64 = 100;             // explicit type\n\n// Functions\nfn add(a: i32, b: i32) -&gt; i32 {\n    a + b                       // no semicolon = return value (expression)\n}\n\n// Conditionals (expressions ‚Äî they return values)\nlet status = if cpu_load &gt; 90 { \"critical\" } else { \"ok\" };\n\n// Loops\nfor item in &collection { }\nfor i in 0..10 { }            // 0 to 9\nfor i in 0..=10 { }           // 0 to 10 (inclusive)\nwhile condition { }\nloop { break value; }          // infinite loop, can return a value\n\n// Printing\nprintln!(\"Hello {name}\");                      // string interpolation\nprintln!(\"Debug: {:?}\", some_struct);           // debug format\nprintln!(\"Pretty debug: {:#?}\", some_struct);   // pretty-printed debug\neprintln!(\"Error: {e}\");                        // print to stderr\n\n// Turbofish (explicit type for generic functions)\nlet nums = \"1,2,3\".split(',').collect::&lt;Vec&lt;&str&gt;&gt;();"
  },
  {
    "objectID": "rust_primer.html#serde-serialization-deserialization",
    "href": "rust_primer.html#serde-serialization-deserialization",
    "title": "Rust Primer for C++/Java Developers",
    "section": "20. Serde: Serialization & Deserialization",
    "text": "20. Serde: Serialization & Deserialization\nSerde is Rust‚Äôs de facto serialization framework. It‚Äôs fast, flexible, and works with JSON, TOML, YAML, MessagePack, and dozens of other formats.\n\nBasic Setup\n# Cargo.toml\n[dependencies]\nserde = { version = \"1.0\", features = [\"derive\"] }\nserde_json = \"1.0\"    # for JSON\ntoml = \"0.8\"          # for TOML\n\n\nDerive Macros: The 90% Case\nuse serde::{Deserialize, Serialize};\n\n#[derive(Debug, Serialize, Deserialize)]\nstruct ServerConfig {\n    hostname: String,\n    port: u16,\n    #[serde(default)]                    // use Default::default() if missing\n    enabled: bool,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    description: Option&lt;String&gt;,\n    #[serde(rename = \"maxConnections\")]  // different name in JSON\n    max_connections: u32,\n}\n\nfn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {\n    // Deserialize from JSON\n    let json = r#\"{\n        \"hostname\": \"node-01\",\n        \"port\": 8080,\n        \"maxConnections\": 1000\n    }\"#;\n\n    let config: ServerConfig = serde_json::from_str(json)?;\n    println!(\"{:?}\", config);\n\n    // Serialize to JSON\n    let output = serde_json::to_string_pretty(&config)?;\n    println!(\"{output}\");\n\n    Ok(())\n}\n\n\nCommon Serde Attributes\n\n\n\n\n\n\n\nAttribute\nEffect\n\n\n\n\n#[serde(rename = \"name\")]\nUse different field name in serialized form\n\n\n#[serde(rename_all = \"camelCase\")]\nRename all fields (struct-level)\n\n\n#[serde(default)]\nUse Default::default() if field missing\n\n\n#[serde(skip)]\nDon‚Äôt serialize or deserialize this field\n\n\n#[serde(skip_serializing)]\nOnly deserialize, not serialize\n\n\n#[serde(skip_serializing_if = \"Option::is_none\")]\nConditionally skip\n\n\n#[serde(flatten)]\nFlatten nested struct into parent\n\n\n#[serde(with = \"module\")]\nUse custom serialize/deserialize functions\n\n\n#[serde(untagged)]\nFor enums: no tag, tries each variant\n\n\n\n\n\nEnums in Serde\n#[derive(Serialize, Deserialize)]\n#[serde(tag = \"type\")]              // \"internally tagged\"\nenum StorageBackend {\n    #[serde(rename = \"local\")]\n    Local { path: String },\n    #[serde(rename = \"s3\")]\n    S3 { bucket: String, region: String },\n}\n\n// Serializes to: {\"type\": \"local\", \"path\": \"/data\"}\n// vs default (externally tagged): {\"Local\": {\"path\": \"/data\"}}\nEnum representations:\n\nExternally tagged (default): {\"Variant\": {...}}\nInternally tagged (#[serde(tag = \"type\")]): {\"type\": \"Variant\", ...}\nAdjacently tagged (#[serde(tag = \"t\", content = \"c\")]): {\"t\": \"Variant\", \"c\": {...}}\nUntagged (#[serde(untagged)]): tries each variant, no tag\n\n\n\nCustom Serialization\nuse serde::{Serializer, Deserializer};\n\n#[derive(Debug)]\nstruct Timestamp(i64);\n\nimpl Serialize for Timestamp {\n    fn serialize&lt;S: Serializer&gt;(&self, serializer: S) -&gt; Result&lt;S::Ok, S::Error&gt; {\n        // Serialize as ISO 8601 string instead of raw i64\n        let datetime = chrono::DateTime::from_timestamp(self.0, 0).unwrap();\n        serializer.serialize_str(&datetime.to_rfc3339())\n    }\n}\n\n\nReading Config Files\nuse std::fs;\n\n// TOML config file\nfn load_toml_config(path: &str) -&gt; Result&lt;ServerConfig, Box&lt;dyn std::error::Error&gt;&gt; {\n    let contents = fs::read_to_string(path)?;\n    let config: ServerConfig = toml::from_str(&contents)?;\n    Ok(config)\n}\n\n// JSON config file\nfn load_json_config(path: &str) -&gt; Result&lt;ServerConfig, Box&lt;dyn std::error::Error&gt;&gt; {\n    let contents = fs::read_to_string(path)?;\n    let config: ServerConfig = serde_json::from_str(&contents)?;\n    Ok(config)\n}\nPractical tip: Use serde_json::Value for dynamic/unknown JSON structures:\nuse serde_json::Value;\n\nlet v: Value = serde_json::from_str(json)?;\nlet hostname = v[\"hostname\"].as_str().unwrap_or(\"unknown\");"
  },
  {
    "objectID": "rust_primer.html#macros",
    "href": "rust_primer.html#macros",
    "title": "Rust Primer for C++/Java Developers",
    "section": "21. Macros",
    "text": "21. Macros\nMacros are code that writes code. Rust has two types: declarative macros (macro_rules!) and procedural macros.\n\nDeclarative Macros (macro_rules!)\nThese are pattern-matching based. You‚Äôve already used them: println!, vec!, format!.\n// Simple macro\nmacro_rules! say_hello {\n    () =&gt; {\n        println!(\"Hello!\");\n    };\n}\n\n// With arguments\nmacro_rules! create_function {\n    ($name:ident) =&gt; {\n        fn $name() {\n            println!(\"Function {:?} was called\", stringify!($name));\n        }\n    };\n}\n\ncreate_function!(foo);  // creates: fn foo() { ... }\ncreate_function!(bar);  // creates: fn bar() { ... }\n\nfn main() {\n    say_hello!();\n    foo();\n    bar();\n}\n\n\nFragment Types (What You Can Match)\n\n\n\n\n\n\n\n\nFragment\nMatches\nExample\n\n\n\n\n$x:ident\nIdentifier\nfoo, my_var\n\n\n$x:expr\nExpression\n1 + 2, foo()\n\n\n$x:ty\nType\ni32, Vec&lt;String&gt;\n\n\n$x:path\nPath\nstd::collections::HashMap\n\n\n$x:stmt\nStatement\nlet x = 1;\n\n\n$x:block\nBlock\n{ ... }\n\n\n$x:item\nItem (fn, struct, etc.)\nfn foo() {}\n\n\n$x:pat\nPattern\nSome(x), _\n\n\n$x:literal\nLiteral\n42, \"hello\"\n\n\n$x:tt\nToken tree (anything)\nany single token or (...), [...], {...}\n\n\n\n\n\nRepetition\n// The vec! macro (simplified)\nmacro_rules! my_vec {\n    // Match zero or more expressions separated by commas\n    ( $( $elem:expr ),* ) =&gt; {\n        {\n            let mut v = Vec::new();\n            $( v.push($elem); )*    // repeat the push for each element\n            v\n        }\n    };\n}\n\nlet nums = my_vec![1, 2, 3, 4, 5];\nRepetition operators: - * ‚Äî zero or more - + ‚Äî one or more - ? ‚Äî zero or one\n\n\nPractical Example: A Logging Macro\nmacro_rules! log_debug {\n    ($($arg:tt)*) =&gt; {\n        #[cfg(debug_assertions)]\n        {\n            eprintln!(\"[DEBUG {}:{}] {}\", file!(), line!(), format!($($arg)*));\n        }\n    };\n}\n\nfn process_data(x: i32) {\n    log_debug!(\"Processing value: {}\", x);\n    // In release builds, this compiles to nothing\n}\n\n\nProcedural Macros (Brief Overview)\nProc macros are more powerful but require a separate crate. There are three types:\n\nDerive macros ‚Äî #[derive(MyTrait)]\nAttribute macros ‚Äî #[my_attribute]\nFunction-like macros ‚Äî my_macro!(...)\n\n// Using a derive macro (you use these all the time)\n#[derive(Debug, Clone, Serialize, Deserialize)]\nstruct MyStruct { ... }\n\n// Using an attribute macro\n#[tokio::main]           // transforms fn main into async runtime setup\nasync fn main() { ... }\n\n#[test]                  // marks function as a test\nfn test_something() { ... }\nWriting proc macros requires the proc_macro, syn (parsing), and quote (code generation) crates:\n// In a separate crate with proc-macro = true in Cargo.toml\nuse proc_macro::TokenStream;\nuse quote::quote;\nuse syn::{parse_macro_input, DeriveInput};\n\n#[proc_macro_derive(MyDebug)]\npub fn my_debug_derive(input: TokenStream) -&gt; TokenStream {\n    let input = parse_macro_input!(input as DeriveInput);\n    let name = input.ident;\n\n    let expanded = quote! {\n        impl std::fmt::Debug for #name {\n            fn fmt(&self, f: &mut std::fmt::Formatter&lt;'_&gt;) -&gt; std::fmt::Result {\n                write!(f, stringify!(#name))\n            }\n        }\n    };\n\n    TokenStream::from(expanded)\n}\n\n\nWhen to Use Macros\nUse declarative macros (macro_rules!) for: - Reducing repetitive code patterns - DSLs (domain-specific languages) - Compile-time code generation - Variadic functions (Rust doesn‚Äôt have them otherwise)\nUse derive macros when: - You need to implement traits automatically - The implementation follows a pattern based on struct/enum structure\nPrefer functions over macros when: - A regular function would work (macros are harder to debug) - You don‚Äôt need compile-time code generation"
  },
  {
    "objectID": "rust_primer.html#unsafe-rust",
    "href": "rust_primer.html#unsafe-rust",
    "title": "Rust Primer for C++/Java Developers",
    "section": "22. Unsafe Rust",
    "text": "22. Unsafe Rust\nunsafe lets you do five things the compiler can‚Äôt verify. It doesn‚Äôt turn off the borrow checker ‚Äî it just gives you access to low-level operations.\n\nWhat Unsafe Allows\n\nDereference raw pointers\nCall unsafe functions/methods\nAccess/modify mutable static variables\nImplement unsafe traits\nAccess fields of unions\n\n\n\nRaw Pointers\nfn main() {\n    let mut x = 10;\n\n    // Creating raw pointers is safe\n    let ptr_immut: *const i32 = &x;       // immutable raw pointer\n    let ptr_mut: *mut i32 = &mut x;       // mutable raw pointer\n\n    // Dereferencing requires unsafe\n    unsafe {\n        println!(\"Value: {}\", *ptr_immut);\n        *ptr_mut = 20;\n        println!(\"New value: {}\", *ptr_mut);\n    }\n}\nRaw pointers: - Are allowed to be null - Don‚Äôt guarantee they point to valid memory - Can have multiple mutable pointers to the same location - Don‚Äôt have lifetimes (no borrow checker enforcement)\n\n\nUnsafe Functions\n// Marked unsafe because caller must ensure preconditions\nunsafe fn dangerous(ptr: *const i32) -&gt; i32 {\n    *ptr    // could crash if ptr is null or invalid\n}\n\nfn main() {\n    let x = 42;\n    let result = unsafe { dangerous(&x) };\n    println!(\"{result}\");\n}\n\n\nSafe Abstractions Over Unsafe Code\nThis is the key pattern: wrap unsafe code in safe interfaces.\nfn split_at_mut(values: &mut [i32], mid: usize) -&gt; (&mut [i32], &mut [i32]) {\n    let len = values.len();\n    let ptr = values.as_mut_ptr();\n\n    assert!(mid &lt;= len);  // safety check\n\n    unsafe {\n        (\n            std::slice::from_raw_parts_mut(ptr, mid),\n            std::slice::from_raw_parts_mut(ptr.add(mid), len - mid),\n        )\n    }\n}\n\n// The function itself is safe because:\n// 1. We validated mid &lt;= len\n// 2. The two slices don't overlap\n// 3. The lifetimes are correctly tied to the input\n\n\nCalling C Functions (FFI)\n// Link to the C standard library\nextern \"C\" {\n    fn abs(input: i32) -&gt; i32;\n    fn strlen(s: *const i8) -&gt; usize;\n}\n\nfn main() {\n    unsafe {\n        println!(\"abs(-5) = {}\", abs(-5));\n    }\n}\nFor proper FFI, use the libc crate and consider bindgen for generating bindings automatically.\n\n\nMutable Static Variables\nstatic mut COUNTER: u32 = 0;\n\nfn increment() {\n    unsafe {\n        COUNTER += 1;\n    }\n}\n\nfn main() {\n    increment();\n    increment();\n    unsafe {\n        println!(\"COUNTER: {COUNTER}\");\n    }\n}\nAvoid mutable statics ‚Äî they‚Äôre a source of data races. Use AtomicU32, Mutex, or lazy_static! / once_cell instead.\n\n\nWhen to Use Unsafe\nLegitimate uses: - FFI (calling C libraries) - Performance-critical code where you can prove safety but the compiler can‚Äôt - Implementing low-level data structures (linked lists, trees with parent pointers) - Interfacing with hardware / OS APIs\nGuidelines: 1. Keep unsafe blocks as small as possible 2. Document the invariants you‚Äôre maintaining 3. Wrap unsafe code in safe abstractions 4. Use #[deny(unsafe_code)] crate-wide, then allow it explicitly where needed\n// Good: minimal unsafe, safe wrapper\npub fn get_unchecked(slice: &[i32], index: usize) -&gt; i32 {\n    // SAFETY: Caller must ensure index &lt; slice.len()\n    unsafe { *slice.get_unchecked(index) }\n}\n\n// Better: don't expose unsafe at all\npub fn get_or_default(slice: &[i32], index: usize, default: i32) -&gt; i32 {\n    slice.get(index).copied().unwrap_or(default)\n}\n\n\nCommon Unsafe Patterns to Know\n// Transmute: reinterpret bytes (very dangerous)\nlet x: i32 = unsafe { std::mem::transmute([0u8, 0, 0, 1]) };\n\n// ManuallyDrop: prevent destructor from running\nlet mut s = std::mem::ManuallyDrop::new(String::from(\"hello\"));\n// s will NOT be dropped when it goes out of scope\n\n// MaybeUninit: uninitialized memory\nuse std::mem::MaybeUninit;\nlet mut x = MaybeUninit::&lt;i32&gt;::uninit();\nunsafe {\n    x.as_mut_ptr().write(42);\n    let val = x.assume_init();  // now safe to use\n}\nBottom line: Most Rust code is 100% safe. You can write entire applications without a single unsafe. But when you need it ‚Äî for FFI, hardware access, or performance ‚Äî it‚Äôs there, and the explicit marking makes it easy to audit."
  },
  {
    "objectID": "rust_primer.html#the-newtype-pattern",
    "href": "rust_primer.html#the-newtype-pattern",
    "title": "Rust Primer for C++/Java Developers",
    "section": "23. The Newtype Pattern",
    "text": "23. The Newtype Pattern\nNewtypes are single-field tuple structs that wrap another type. They provide type safety with zero runtime cost.\n\nBasic Newtype\n// Without newtypes: easy to mix up arguments\nfn create_server(rack_id: String, host_id: String, port: u32) { ... }\n\ncreate_server(host_id, rack_id, port);  // Oops! Swapped arguments, compiles fine\n\n// With newtypes: compile-time safety\npub struct RackId(pub String);\npub struct HostId(pub String);\npub struct Port(pub u32);\n\nfn create_server(rack: RackId, host: HostId, port: Port) { ... }\n\ncreate_server(host_id, rack_id, port);  // COMPILE ERROR: expected RackId, found HostId\n\n\nImplementing Common Traits\n#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]\npub struct UserId(pub String);\n\nimpl UserId {\n    pub fn new(id: impl Into&lt;String&gt;) -&gt; Self {\n        UserId(id.into())\n    }\n\n    pub fn as_str(&self) -&gt; &str {\n        &self.0\n    }\n}\n\nimpl std::fmt::Display for UserId {\n    fn fmt(&self, f: &mut std::fmt::Formatter&lt;'_&gt;) -&gt; std::fmt::Result {\n        write!(f, \"{}\", self.0)\n    }\n}\n\n// Allow easy conversion from string types\nimpl&lt;S: Into&lt;String&gt;&gt; From&lt;S&gt; for UserId {\n    fn from(s: S) -&gt; Self {\n        UserId(s.into())\n    }\n}\n\n\nMeasurement Types\nNewtypes shine for units of measurement:\n#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]\npub struct Meters(pub u32);\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]\npub struct Feet(pub u32);\n\n// Can't accidentally add meters to feet\nimpl std::ops::Add for Meters {\n    type Output = Self;\n    fn add(self, other: Self) -&gt; Self {\n        Meters(self.0 + other.0)\n    }\n}\n\n// Implement Sum for iterator collection\nimpl std::iter::Sum for Meters {\n    fn sum&lt;I: Iterator&lt;Item = Self&gt;&gt;(iter: I) -&gt; Self {\n        Meters(iter.map(|m| m.0).sum())\n    }\n}\n\n// Now you can do:\nlet distances = vec![Meters(10), Meters(20), Meters(30)];\nlet total: Meters = distances.into_iter().sum();  // Meters(60)\n\n\nDeref for Transparent Access\nUse Deref sparingly ‚Äî it provides transparent access to the inner type:\nuse std::ops::Deref;\n\npub struct Email(String);\n\nimpl Deref for Email {\n    type Target = str;\n    fn deref(&self) -&gt; &str {\n        &self.0\n    }\n}\n\nlet email = Email(\"user@example.com\".into());\nprintln!(\"Length: {}\", email.len());  // Can call str methods directly\nWarning: Deref weakens type safety. Use it when the newtype is truly just a wrapper with the same semantics, not when you want distinct behavior."
  },
  {
    "objectID": "rust_primer.html#phantomdata-and-marker-traits",
    "href": "rust_primer.html#phantomdata-and-marker-traits",
    "title": "Rust Primer for C++/Java Developers",
    "section": "24. PhantomData and Marker Traits",
    "text": "24. PhantomData and Marker Traits\nThese are advanced type-level programming tools for encoding constraints without runtime cost.\n\nPhantomData\nPhantomData&lt;T&gt; tells the compiler ‚Äúthis type logically contains a T‚Äù without actually storing one. Used when types need to track type information at compile time.\nuse std::marker::PhantomData;\n\n// A typed ID that tracks what entity it refers to\npub struct Id&lt;T&gt; {\n    value: u64,\n    _phantom: PhantomData&lt;T&gt;,  // zero-sized, no runtime cost\n}\n\nstruct User;\nstruct Order;\n\nimpl&lt;T&gt; Id&lt;T&gt; {\n    fn new(value: u64) -&gt; Self {\n        Id { value, _phantom: PhantomData }\n    }\n}\n\nlet user_id: Id&lt;User&gt; = Id::new(42);\nlet order_id: Id&lt;Order&gt; = Id::new(42);\n\n// These are different types despite having the same value!\n// fn process_user(id: Id&lt;User&gt;) { ... }\n// process_user(order_id);  // COMPILE ERROR\n\n\nType-Safe Links with PhantomData\nuse std::marker::PhantomData;\n\npub trait Port: Clone {}\npub trait Cable: Clone {}\n\n// A link between two ports via a cable, fully type-safe\npub struct Link&lt;PA: Port, C: Cable, PB: Port&gt; {\n    port_a_id: String,\n    port_b_id: String,\n    _phantom: PhantomData&lt;(PA, C, PB)&gt;,\n}\n\nimpl&lt;PA: Port, C: Cable, PB: Port&gt; Link&lt;PA, C, PB&gt; {\n    pub fn new(a: String, b: String) -&gt; Self {\n        Link {\n            port_a_id: a,\n            port_b_id: b,\n            _phantom: PhantomData,\n        }\n    }\n}\n\n\nMarker Traits\nEmpty traits that categorize types without adding behavior:\n// Marker traits for action targeting\npub trait ServerHostMarker {}\npub trait SwitchHostMarker {}\n\n// Only servers implement this\nimpl ServerHostMarker for ServerHost {}\n\n// Only switches implement this\nimpl SwitchHostMarker for SwitchHost {}\n\n// Action that only works on servers\npub struct InstallOS&lt;H: ServerHostMarker&gt; {\n    os_image: String,\n    _phantom: PhantomData&lt;H&gt;,\n}\n\n// Universal marker with blanket implementation\npub trait UniversalHostMarker {}\nimpl&lt;H&gt; UniversalHostMarker for H {}  // All types get this\n\n\nCommon Standard Library Markers\n\n\n\nMarker\nMeaning\n\n\n\n\nSend\nSafe to transfer between threads\n\n\nSync\nSafe to share references between threads\n\n\nSized\nHas known size at compile time (implicit bound)\n\n\nUnpin\nCan be safely moved after being pinned\n\n\nCopy\nCan be implicitly copied (bitwise)"
  },
  {
    "objectID": "rust_primer.html#downcasting-trait-objects",
    "href": "rust_primer.html#downcasting-trait-objects",
    "title": "Rust Primer for C++/Java Developers",
    "section": "25. Downcasting Trait Objects",
    "text": "25. Downcasting Trait Objects\nWhen you have a dyn Trait and need to get the concrete type back, use the Any trait.\n\nThe Pattern\nuse std::any::Any;\n\npub trait Host: std::fmt::Debug + Send + Sync + Any {\n    fn hostname(&self) -&gt; &str;\n\n    // Required for downcasting\n    fn as_any(&self) -&gt; &dyn Any;\n    fn as_any_mut(&mut self) -&gt; &mut dyn Any;\n}\n\n#[derive(Debug)]\npub struct ServerHost {\n    pub hostname: String,\n    pub cpu_cores: u32,\n}\n\nimpl Host for ServerHost {\n    fn hostname(&self) -&gt; &str {\n        &self.hostname\n    }\n\n    fn as_any(&self) -&gt; &dyn Any {\n        self\n    }\n\n    fn as_any_mut(&mut self) -&gt; &mut dyn Any {\n        self\n    }\n}\n\n#[derive(Debug)]\npub struct SwitchHost {\n    pub hostname: String,\n    pub port_count: u32,\n}\n\nimpl Host for SwitchHost {\n    fn hostname(&self) -&gt; &str {\n        &self.hostname\n    }\n\n    fn as_any(&self) -&gt; &dyn Any {\n        self\n    }\n\n    fn as_any_mut(&mut self) -&gt; &mut dyn Any {\n        self\n    }\n}\n\n\nUsing Downcasting\nfn process_host(host: &dyn Host) {\n    println!(\"Processing: {}\", host.hostname());\n\n    // Try to downcast to ServerHost\n    if let Some(server) = host.as_any().downcast_ref::&lt;ServerHost&gt;() {\n        println!(\"  Server with {} cores\", server.cpu_cores);\n    }\n    // Try to downcast to SwitchHost\n    else if let Some(switch) = host.as_any().downcast_ref::&lt;SwitchHost&gt;() {\n        println!(\"  Switch with {} ports\", switch.port_count);\n    }\n}\n\nfn main() {\n    let hosts: Vec&lt;Box&lt;dyn Host&gt;&gt; = vec![\n        Box::new(ServerHost { hostname: \"srv-01\".into(), cpu_cores: 64 }),\n        Box::new(SwitchHost { hostname: \"sw-01\".into(), port_count: 48 }),\n    ];\n\n    for host in &hosts {\n        process_host(host.as_ref());\n    }\n}\n\n\nCloning Trait Objects\nStandard Clone doesn‚Äôt work with trait objects. Use the clone_box pattern:\npub trait Host: std::fmt::Debug {\n    fn clone_box(&self) -&gt; Box&lt;dyn Host&gt;;\n    // ... other methods\n}\n\nimpl Clone for Box&lt;dyn Host&gt; {\n    fn clone(&self) -&gt; Self {\n        self.clone_box()\n    }\n}\n\nimpl Host for ServerHost {\n    fn clone_box(&self) -&gt; Box&lt;dyn Host&gt; {\n        Box::new(self.clone())\n    }\n}"
  },
  {
    "objectID": "rust_primer.html#cargo-workspaces",
    "href": "rust_primer.html#cargo-workspaces",
    "title": "Rust Primer for C++/Java Developers",
    "section": "26. Cargo Workspaces",
    "text": "26. Cargo Workspaces\nFor larger projects, organize multiple related crates in a workspace.\n\nWorkspace Structure\nmy-project/\n‚îú‚îÄ‚îÄ Cargo.toml              # Workspace root\n‚îú‚îÄ‚îÄ crates/\n‚îÇ   ‚îú‚îÄ‚îÄ my-core/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Cargo.toml\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ src/lib.rs\n‚îÇ   ‚îú‚îÄ‚îÄ my-cli/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Cargo.toml\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ src/main.rs\n‚îÇ   ‚îî‚îÄ‚îÄ my-macros/\n‚îÇ       ‚îú‚îÄ‚îÄ Cargo.toml\n‚îÇ       ‚îî‚îÄ‚îÄ src/lib.rs\n‚îî‚îÄ‚îÄ examples/\n    ‚îî‚îÄ‚îÄ demo/\n        ‚îú‚îÄ‚îÄ Cargo.toml\n        ‚îî‚îÄ‚îÄ src/main.rs\n\n\nRoot Cargo.toml\n[workspace]\nresolver = \"2\"\nmembers = [\n    \"crates/my-core\",\n    \"crates/my-cli\",\n    \"crates/my-macros\",\n    \"examples/demo\",\n]\n\n# Shared dependencies with consistent versions\n[workspace.dependencies]\nserde = { version = \"1.0\", features = [\"derive\"] }\nserde_json = \"1.0\"\nthiserror = \"1.0\"\nclap = { version = \"4.5\", features = [\"derive\"] }\ntokio = { version = \"1.0\", features = [\"full\"] }\n\n# Internal crates as workspace dependencies\nmy-core = { path = \"crates/my-core\" }\nmy-macros = { path = \"crates/my-macros\" }\n\n\nCrate Cargo.toml\n[package]\nname = \"my-cli\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[dependencies]\n# Use workspace versions\nserde.workspace = true\nserde_json.workspace = true\nclap.workspace = true\n\n# Internal dependencies\nmy-core.workspace = true\n\n\nBenefits\n\nShared dependencies: One version across all crates\nUnified builds: cargo build builds everything\nShared target directory: Faster incremental compilation\nCross-crate testing: Run all tests with cargo test --workspace\n\n\n\nProc-Macro Crates\nProcedural macros must be in their own crate:\n# crates/my-macros/Cargo.toml\n[package]\nname = \"my-macros\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[lib]\nproc-macro = true\n\n[dependencies]\nsyn = { version = \"2.0\", features = [\"full\"] }\nquote = \"1.0\"\nproc-macro2 = \"1.0\"\nThen re-export from your main crate:\n// crates/my-core/src/lib.rs\npub use my_macros::my_derive_macro;"
  },
  {
    "objectID": "rust_primer.html#what-to-learn-next",
    "href": "rust_primer.html#what-to-learn-next",
    "title": "Rust Primer for C++/Java Developers",
    "section": "27. What to Learn Next",
    "text": "27. What to Learn Next\nOnce you‚Äôre comfortable with the above, these are the next frontiers:\n\nAsync Rust in depth: Tokio runtime, futures, select!, streams, async traits\nError handling patterns: thiserror for libraries, anyhow for applications\nPinning: Required for self-referential types in async code\nAdvanced FFI: bindgen for auto-generating C bindings, cbindgen for exposing Rust to C\nEmbedded Rust: no_std, bare metal programming\nSIMD and performance: std::simd, profiling with perf, criterion for benchmarks\nThe std docs: Genuinely excellent ‚Äî https://doc.rust-lang.org/std/\n\n\nBest way to learn: Pick a small project (a CLI tool, a simple HTTP server with axum/actix, a file processor) and just build. The compiler errors are famously helpful ‚Äî read them carefully, they usually tell you exactly what to do."
  },
  {
    "objectID": "ipsec_primer.html",
    "href": "ipsec_primer.html",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "",
    "text": "Goal: Get you to ~80% of IPSec, fast. Assumes you understand TCP/IP, basic networking, and encryption concepts. Skips: Quantum-resistant algorithms, custom IKE implementations, deep cryptographic theory, mobile IPSec (MOBIKE)."
  },
  {
    "objectID": "ipsec_primer.html#what-is-ipsec-and-why-does-it-exist",
    "href": "ipsec_primer.html#what-is-ipsec-and-why-does-it-exist",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "1. What is IPSec and Why Does It Exist?",
    "text": "1. What is IPSec and Why Does It Exist?\nThe Problem: Standard IP packets travel in plaintext. Anyone along the path can: - Read your data (no confidentiality) - Modify packets (no integrity) - Impersonate endpoints (no authentication) - Replay old packets (no replay protection)\nThe Solution: IPSec is a suite of protocols that secures IP communications at the network layer (Layer 3).\nAnalogy: If TLS/SSL is like sending a letter in a locked box (application layer), IPSec is like encrypting everything that goes on the road (network layer). It‚Äôs transparent to applications.\nKey Benefits: - Confidentiality: Encryption (AES, ChaCha20) - Integrity: Hashing (SHA-256, SHA-512) - Authentication: Prove who you are (certificates, PSK) - Anti-replay: Sequence numbers prevent replay attacks"
  },
  {
    "objectID": "ipsec_primer.html#the-big-picture-ipsec-architecture",
    "href": "ipsec_primer.html#the-big-picture-ipsec-architecture",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "2. The Big Picture: IPSec Architecture",
    "text": "2. The Big Picture: IPSec Architecture\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ         IPSec Architecture              ‚îÇ\n‚îÇ                                         ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n‚îÇ  ‚îÇ  IKE (Control Plane)             ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ  - Negotiates parameters         ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ  - Establishes Security Assoc.   ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ  - Key exchange                  ‚îÇ  ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n‚îÇ              ‚Üì creates                  ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n‚îÇ  ‚îÇ  IPSec Protocols (Data Plane)    ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ  - AH: Authentication Header     ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ  - ESP: Encapsulating Security   ‚îÇ  ‚îÇ\n‚îÇ  ‚îÇ         Payload                  ‚îÇ  ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\nTwo Main Components:\n\nIKE (Internet Key Exchange): The negotiator\n\nSets up the secure tunnel\nExchanges keys\nAgrees on algorithms\n\nIPSec Protocols: The workers\n\nAH: Authenticates but doesn‚Äôt encrypt\nESP: Encrypts AND authenticates (most common)\n\n\nMental Model: IKE is the handshake before a phone call. AH/ESP is the secure phone call itself."
  },
  {
    "objectID": "ipsec_primer.html#ipsec-protocols-ah-vs-esp",
    "href": "ipsec_primer.html#ipsec-protocols-ah-vs-esp",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "3. IPSec Protocols: AH vs ESP",
    "text": "3. IPSec Protocols: AH vs ESP\n\nAuthentication Header (AH)\nWhat it does: Provides authentication and integrity, but NOT encryption.\nUse case: When you need to verify the sender and ensure data wasn‚Äôt tampered with, but encryption is not required (or handled elsewhere).\nPacket Structure:\n[ IP Header | AH Header | Original Payload ]\n             ‚Üë\n             Authenticates everything\nRarely used today because ESP can do everything AH does plus encryption.\n\n\nEncapsulating Security Payload (ESP)\nWhat it does: Provides encryption, authentication, and integrity.\nThis is what you‚Äôll use 99% of the time.\nPacket Structure:\n[ IP Header | ESP Header | Encrypted Payload | ESP Trailer | ESP Auth ]\n             ‚Üë                                              ‚Üë\n             |-------- Encrypted ---------|                |\n             |------------- Authenticated -----------------|\nESP protects: - Payload (encrypted) - ESP header + payload + trailer (authenticated)\nESP does NOT protect: - Original IP header (that would break routing)"
  },
  {
    "objectID": "ipsec_primer.html#ipsec-modes-transport-vs-tunnel",
    "href": "ipsec_primer.html#ipsec-modes-transport-vs-tunnel",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "4. IPSec Modes: Transport vs Tunnel",
    "text": "4. IPSec Modes: Transport vs Tunnel\n\nTransport Mode\nWhat it does: Protects only the payload, keeps original IP headers.\nBefore:\n[ IP Header | TCP/UDP | Data ]\n\nAfter (ESP Transport):\n[ IP Header | ESP Header | TCP/UDP | Data | ESP Trailer | ESP Auth ]\n  ‚Üë Original                    ‚Üë Encrypted\nUse case: Host-to-host communication (e.g., server to server in same network).\nAnalogy: Like putting a lock on a package but keeping the shipping label visible.\n\n\nTunnel Mode\nWhat it does: Encrypts the ENTIRE original packet, adds new IP header.\nBefore:\n[ IP Header | TCP/UDP | Data ]\n\nAfter (ESP Tunnel):\n[ New IP Header | ESP Header | Original IP Header | TCP/UDP | Data | ESP Trailer | ESP Auth ]\n                               ‚Üë Encrypted\nUse case: Site-to-site VPNs, gateway-to-gateway.\nAnalogy: Like putting the entire package (including original label) inside a new box with a new shipping label.\nMost common mode for VPNs."
  },
  {
    "objectID": "ipsec_primer.html#ike-the-negotiation-protocol",
    "href": "ipsec_primer.html#ike-the-negotiation-protocol",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "5. IKE: The Negotiation Protocol",
    "text": "5. IKE: The Negotiation Protocol\nIKE sets up IPSec tunnels. There are two versions:\n\nIKEv1 (Legacy)\nTwo phases: - Phase 1: Establish secure channel (ISAKMP SA) - Main Mode (6 messages, more secure) - Aggressive Mode (3 messages, faster but less secure) - Phase 2: Negotiate IPSec parameters (IPSec SA) - Quick Mode\n\n\nIKEv2 (Modern, Preferred)\nSimpler: 4 messages to establish both IKE SA and IPSec SA.\nIKEv2 Advantages: - Faster (fewer round trips) - Built-in NAT traversal (NAT-T) - Mobility support (MOBIKE) - Better error handling - Mandatory certificate support\nAlways use IKEv2 if possible.\n\n\nIKE Exchange (Simplified)\nInitiator                           Responder\n    |                                   |\n    |--- IKE_SA_INIT (proposals) ------&gt;|\n    |&lt;-- IKE_SA_INIT (chosen params) ---|\n    |                                   |\n    |--- IKE_AUTH (authenticate) ------&gt;|\n    |&lt;-- IKE_AUTH (authenticate) -------|\n    |                                   |\n    | IPSec tunnel established!         |\n    |&lt;======= Encrypted traffic =======&gt;|\nWhat‚Äôs negotiated: - Encryption algorithm (AES-256, AES-128, etc.) - Hash algorithm (SHA-256, SHA-512, etc.) - Diffie-Hellman group (key exchange strength) - Authentication method (PSK, certificates) - Lifetime (when to rekey)"
  },
  {
    "objectID": "ipsec_primer.html#security-associations-sas",
    "href": "ipsec_primer.html#security-associations-sas",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "6. Security Associations (SAs)",
    "text": "6. Security Associations (SAs)\nA Security Association is a one-way agreement on security parameters.\nThink of it as: A contract that says ‚Äúwhen sending packets, use AES-256 + SHA-256 with this key.‚Äù\n\nKey Points\n\nUnidirectional: Each direction needs its own SA\n\nA ‚Üí B: One SA\nB ‚Üí A: Different SA\n\nIdentified by SPI (Security Parameter Index)\n\n32-bit number in ESP/AH header\nReceiver uses SPI to look up which SA to use\n\nTwo types:\n\nIKE SA: For IKE negotiation (Phase 1)\nIPSec SA: For actual data (Phase 2)\n\n\n\n\nSA Database (SAD)\nEach endpoint maintains a database of active SAs:\nSPI: 0x12345678\nProtocol: ESP\nMode: Tunnel\nEncryption: AES-256-GCM\nIntegrity: Built-in (GCM)\nKeys: [encryption key, integrity key]\nSource: 10.1.1.1\nDestination: 10.2.2.2\nLifetime: 3600 seconds"
  },
  {
    "objectID": "ipsec_primer.html#security-policy-database-spd",
    "href": "ipsec_primer.html#security-policy-database-spd",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "7. Security Policy Database (SPD)",
    "text": "7. Security Policy Database (SPD)\nSPD defines WHEN to use IPSec.\nRules look like: - Traffic from 10.1.0.0/24 to 10.2.0.0/24 ‚Üí Use IPSec (tunnel to 203.0.113.1) - Traffic to 8.8.8.8 ‚Üí Bypass IPSec (allow plaintext) - All other traffic ‚Üí Drop\nAnalogy: SPD is the firewall rules. SAD is the active connections.\nExample SPD Entry:\nSource: 192.168.1.0/24\nDestination: 192.168.2.0/24\nProtocol: Any\nAction: Protect with IPSec (ESP, Tunnel mode)\nTunnel endpoint: 203.0.113.10"
  },
  {
    "objectID": "ipsec_primer.html#encryption-authentication-algorithms",
    "href": "ipsec_primer.html#encryption-authentication-algorithms",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "8. Encryption & Authentication Algorithms",
    "text": "8. Encryption & Authentication Algorithms\n\nEncryption Algorithms\nModern (use these): - AES-GCM-256: Combined encryption + authentication (AEAD) - AES-GCM-128: Faster, still secure - ChaCha20-Poly1305: Great for mobile/ARM devices\nLegacy (avoid): - 3DES: Slow, weak - AES-CBC: Needs separate integrity algorithm\nRecommendation: AES-GCM (128 or 256 bit). It‚Äôs fast, secure, and widely supported.\n\n\nHash/Integrity Algorithms\nModern: - SHA-256 - SHA-512 - HMAC-SHA-256\nLegacy (avoid): - MD5: Broken - SHA-1: Deprecated\nNote: With AEAD ciphers like AES-GCM, integrity is built-in.\n\n\nDiffie-Hellman Groups\nUsed for key exchange. Higher number = stronger but slower.\nModern: - Group 14 (2048-bit): Minimum for new deployments - Group 19 (256-bit ECC): Fast and secure - Group 20 (384-bit ECC): Even stronger\nLegacy (avoid): - Group 1, 2, 5: Too weak"
  },
  {
    "objectID": "ipsec_primer.html#authentication-methods",
    "href": "ipsec_primer.html#authentication-methods",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "9. Authentication Methods",
    "text": "9. Authentication Methods\n\nPre-Shared Key (PSK)\nWhat: Both sides have the same secret password.\nipsec.conf (Linux strongSwan):\nconn mytunnel\n    authby=secret\n    left=10.1.1.1\n    right=10.2.2.2\n\nipsec.secrets:\n10.1.1.1 10.2.2.2 : PSK \"mysupersecretkey123\"\nPros: Simple to set up Cons: - Doesn‚Äôt scale (need different PSK for each peer) - PSK must be shared securely - No identity verification beyond ‚Äúknows the password‚Äù\nUse for: Small deployments, testing\n\n\nCertificates (RSA/ECDSA)\nWhat: Each side has a certificate signed by a trusted CA.\nPros: - Scales well (distribute CA cert, not individual secrets) - Strong identity verification - Can revoke compromised certs (CRL/OCSP)\nCons: More complex setup (PKI infrastructure)\nUse for: Production, large deployments\nCertificate-based flow: 1. Each peer has a private key + certificate 2. Certificates signed by same CA (or trusted CAs) 3. During IKE, peers exchange certificates 4. Each verifies the other‚Äôs certificate against CA 5. If valid, authenticate using private key"
  },
  {
    "objectID": "ipsec_primer.html#nat-traversal-nat-t",
    "href": "ipsec_primer.html#nat-traversal-nat-t",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "10. NAT Traversal (NAT-T)",
    "text": "10. NAT Traversal (NAT-T)\nProblem: IPSec uses protocol 50 (ESP) and 51 (AH), not TCP/UDP. NAT routers don‚Äôt know how to handle them.\nSolution: NAT-T encapsulates ESP in UDP (port 4500).\nWithout NAT-T:\n[ IP | ESP | Payload ]  ‚Üê NAT breaks this\n\nWith NAT-T:\n[ IP | UDP (4500) | ESP | Payload ]  ‚Üê NAT can handle UDP\nIKEv2 has NAT-T built-in. IKEv1 needs explicit configuration.\nAuto-detection: IKE detects NAT and automatically enables NAT-T."
  },
  {
    "objectID": "ipsec_primer.html#practical-example-site-to-site-vpn",
    "href": "ipsec_primer.html#practical-example-site-to-site-vpn",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "11. Practical Example: Site-to-Site VPN",
    "text": "11. Practical Example: Site-to-Site VPN\n\nScenario\nSite A                 Internet               Site B\n10.1.0.0/24  ‚Üê‚Üí  [GW-A] ‚Üê--IPSec--‚Üí [GW-B] ‚Üê‚Üí  10.2.0.0/24\n                203.0.113.1      203.0.113.2\nGoal: Hosts in Site A can talk to hosts in Site B securely.\n\n\nConfiguration (strongSwan on Linux)\nGateway A (/etc/ipsec.conf):\nconfig setup\n    charondebug=\"ike 2, knl 2, cfg 2\"\n\nconn site-to-site\n    # Connection basics\n    auto=start\n    type=tunnel\n    keyexchange=ikev2\n\n    # Authentication\n    authby=secret\n\n    # Local (Site A)\n    left=203.0.113.1\n    leftsubnet=10.1.0.0/24\n    leftid=@site-a\n\n    # Remote (Site B)\n    right=203.0.113.2\n    rightsubnet=10.2.0.0/24\n    rightid=@site-b\n\n    # IKE (Phase 1) proposal\n    ike=aes256-sha256-modp2048!\n\n    # ESP (Phase 2) proposal\n    esp=aes256gcm16-modp2048!\n\n    # Lifetimes\n    ikelifetime=28800s\n    lifetime=3600s\n\n    # Dead Peer Detection\n    dpdaction=restart\n    dpddelay=30s\nGateway A (/etc/ipsec.secrets):\n@site-a @site-b : PSK \"MySharedSecretKey12345\"\nGateway B: Mirror configuration (swap left/right).\n\n\nExplanation\n\nkeyexchange=ikev2: Use IKEv2 (modern)\ntype=tunnel: Tunnel mode (encrypt entire packet)\nleftsubnet/rightsubnet: Which networks to protect\nike=: Phase 1 algorithms (AES-256, SHA-256, DH group 14)\nesp=: Phase 2 algorithms (AES-256-GCM)\n!: Enforces this proposal (no fallback to weaker)\ndpdaction: Detect and restart dead tunnels\n\n\n\nTesting\n# Start IPSec\nipsec start\n\n# Check status\nipsec status\n\n# From Site A, ping Site B host\nping 10.2.0.1\n\n# Check SAs\nip xfrm state\nip xfrm policy"
  },
  {
    "objectID": "ipsec_primer.html#practical-example-road-warrior-vpn",
    "href": "ipsec_primer.html#practical-example-road-warrior-vpn",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "12. Practical Example: Road Warrior VPN",
    "text": "12. Practical Example: Road Warrior VPN\n\nScenario\nRemote user (laptop, phone) connects to corporate network.\nRoad Warrior              Corporate Network\n(Dynamic IP)  ‚Üê--IPSec--‚Üí  VPN Gateway  ‚Üê‚Üí  10.0.0.0/8\n                           203.0.113.10\n\n\nServer Configuration (strongSwan)\nconn roadwarrior\n    auto=add\n    type=tunnel\n    keyexchange=ikev2\n\n    # Server side\n    left=203.0.113.10\n    leftsubnet=10.0.0.0/8\n    leftcert=server.crt\n\n    # Client side\n    right=%any\n    rightsourceip=10.255.0.0/16  # IP pool for clients\n\n    # Authentication\n    leftauth=pubkey\n    rightauth=eap-mschapv2  # Username/password\n    eap_identity=%identity\n\n    # Proposals\n    ike=aes256-sha256-modp2048!\n    esp=aes256gcm16!\n\n\nClient Configuration\nLinux/strongSwan:\nconn corporate\n    auto=start\n    right=203.0.113.10\n    rightsubnet=10.0.0.0/8\n    rightid=@vpn.company.com\n\n    # Client auth\n    leftsourceip=%config\n    eap_identity=user@company.com\n\n    ike=aes256-sha256-modp2048!\n    esp=aes256gcm16!\nClient secrets (/etc/ipsec.secrets):\nuser@company.com : EAP \"MyPassword123\"\n\n\nMobile Clients\niOS/macOS: Built-in IKEv2 support Android: strongSwan app or built-in\nConfiguration via profiles or manual setup: - Server: vpn.company.com - Remote ID: @vpn.company.com - Username/password or certificate"
  },
  {
    "objectID": "ipsec_primer.html#perfect-forward-secrecy-pfs",
    "href": "ipsec_primer.html#perfect-forward-secrecy-pfs",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "13. Perfect Forward Secrecy (PFS)",
    "text": "13. Perfect Forward Secrecy (PFS)\nProblem: If an attacker records encrypted traffic and later steals the long-term key, they can decrypt all past sessions.\nSolution: PFS uses ephemeral keys for each session. Even if long-term key is compromised, past sessions remain secure.\nHow: Diffie-Hellman key exchange in Phase 2 (not just Phase 1).\nConfiguration:\n# Without PFS\nesp=aes256gcm16!\n\n# With PFS (add DH group)\nesp=aes256gcm16-modp2048!\nTrade-off: Slightly slower (extra DH exchange per rekey).\nRecommendation: Always use PFS in production."
  },
  {
    "objectID": "ipsec_primer.html#dead-peer-detection-dpd",
    "href": "ipsec_primer.html#dead-peer-detection-dpd",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "14. Dead Peer Detection (DPD)",
    "text": "14. Dead Peer Detection (DPD)\nProblem: If tunnel endpoint crashes or network fails, the other end doesn‚Äôt know. Tunnel appears up but traffic is blackholed.\nSolution: DPD sends periodic keepalives.\ndpdaction=restart      # restart | clear | hold\ndpddelay=30s          # check every 30 seconds\ndpdtimeout=120s       # declare dead after 120s\nActions: - restart: Restart tunnel - clear: Delete tunnel - hold: Keep SA but don‚Äôt send traffic"
  },
  {
    "objectID": "ipsec_primer.html#troubleshooting-ipsec",
    "href": "ipsec_primer.html#troubleshooting-ipsec",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "15. Troubleshooting IPSec",
    "text": "15. Troubleshooting IPSec\n\nCommon Issues\n\n1. Tunnel Not Establishing\nCheck:\n# View logs\nipsec statusall\njournalctl -u ipsec -f\n\n# Common causes:\n# - Firewall blocking UDP 500, 4500, ESP (protocol 50)\n# - Mismatched proposals (encryption/hash algorithms)\n# - PSK mismatch\n# - Time sync issues (certificates)\nFix: Verify both sides have matching proposals.\n\n\n2. Tunnel Up But No Traffic\nCheck:\n# Verify SAs exist\nip xfrm state\nsetkey -D  # (BSD/macOS)\n\n# Verify policies\nip xfrm policy\n\n# Ping with tcpdump\ntcpdump -i any esp\nCommon causes: - SPD not configured correctly - Routing issues (packets not reaching IPSec gateway) - Firewall on destination blocking traffic\n\n\n3. Tunnel Flapping\nCheck: - DPD too aggressive - Network instability - Rekeying issues\nFix:\n# Increase DPD timers\ndpddelay=60s\ndpdtimeout=300s\n\n# Increase lifetimes\nikelifetime=86400s\nlifetime=28800s\n\n\n4. NAT Issues\nSymptoms: Tunnel works initially, then stops after idle.\nCause: NAT dropping UDP session.\nFix:\n# Enable DPD to keep NAT session alive\ndpddelay=30s\n\n# Or reduce lifetime to force rekey\nlifetime=1800s\n\n\n\nDebug Commands\n# strongSwan\nipsec statusall          # Overall status\nipsec listcerts          # Certificates\nipsec listcacerts        # CA certificates\nipsec listsas            # Security associations\nipsec listpolicies       # Policies\n\n# Linux kernel\nip xfrm state            # SAs\nip xfrm policy           # SPD\nip -s xfrm state         # Stats\n\n# BSD/macOS\nsetkey -D                # SAs\nsetkey -DP               # Policies\n\n# Packet capture\ntcpdump -i any -n esp    # ESP packets\ntcpdump -i any -n udp port 500 or udp port 4500  # IKE\n\n\nWireshark\nDecrypt ESP traffic in Wireshark: 1. Edit ‚Üí Preferences ‚Üí Protocols ‚Üí ESP 2. Add SA: SPI, encryption key, auth key"
  },
  {
    "objectID": "ipsec_primer.html#performance-considerations",
    "href": "ipsec_primer.html#performance-considerations",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "16. Performance Considerations",
    "text": "16. Performance Considerations\n\nHardware Acceleration\nModern CPUs have AES-NI (AES instructions).\nCheck:\n# Linux\ngrep aes /proc/cpuinfo\n\n# Enable AES-NI in strongSwan\nipsec pki --gen --type rsa --outform pem &gt; private.key\nPerformance: AES-NI can achieve 10+ Gbps on modern CPUs.\n\n\nAlgorithm Choice\nFastest (with AES-NI): - AES-128-GCM: ~10-20 Gbps - AES-256-GCM: ~7-15 Gbps\nWithout AES-NI: - ChaCha20-Poly1305: Often faster than AES\nSlowest: - 3DES: ~100 Mbps (avoid!)\n\n\nJumbo Frames\nIPSec adds overhead (50-80 bytes). With 1500 MTU, effective payload drops to ~1420.\nSolutions: 1. MSS Clamping: Reduce TCP MSS bash    iptables -A FORWARD -p tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu\n\nIncrease MTU: Use 9000 MTU (jumbo frames) if network supports\nPath MTU Discovery: Let TCP figure it out (can be slow)"
  },
  {
    "objectID": "ipsec_primer.html#security-best-practices",
    "href": "ipsec_primer.html#security-best-practices",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "17. Security Best Practices",
    "text": "17. Security Best Practices\n\n‚úÖ Do This\n\nUse IKEv2\n\nFaster, more secure than IKEv1\n\nUse Strong Crypto\nike=aes256gcm16-sha256-modp2048!\nesp=aes256gcm16-modp2048!\nEnable PFS\n\nInclude DH group in ESP proposal\n\nUse Certificates\n\nNot PSK (except for testing/small deployments)\n\nRegular Rekeying\nikelifetime=28800s   # 8 hours\nlifetime=3600s       # 1 hour\nMonitor and Log\n\nEnable logging\nMonitor tunnel status\nAlert on flapping tunnels\n\n\n\n\n‚ùå Don‚Äôt Do This\n\nWeak Algorithms\n\nNo 3DES, MD5, SHA-1\nNo DH group 1, 2, 5\n\nNo PFS\n\nAlways use ephemeral DH in Phase 2\n\nLong Lifetimes\n\nDon‚Äôt set lifetime to days/weeks\n\nAggressive Mode (IKEv1)\n\nLeaks identity, vulnerable to dictionary attacks\n\nOverly Permissive SPD\n\nBe specific about what traffic needs IPSec"
  },
  {
    "objectID": "ipsec_primer.html#ipsec-vs-other-vpn-technologies",
    "href": "ipsec_primer.html#ipsec-vs-other-vpn-technologies",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "18. IPSec vs Other VPN Technologies",
    "text": "18. IPSec vs Other VPN Technologies\n\nIPSec vs OpenVPN\n\n\n\n\n\n\n\n\nFeature\nIPSec\nOpenVPN\n\n\n\n\nLayer\nLayer 3 (IP)\nLayer 2/3 (TUN/TAP)\n\n\nPerformance\nFaster (kernel space, HW accel)\nSlower (userspace)\n\n\nNAT Traversal\nBuilt-in (NAT-T)\nNatural (uses UDP/TCP)\n\n\nSetup\nComplex\nSimpler\n\n\nFirewall\nHarder (ESP)\nEasier (TCP 443)\n\n\nMobile\nExcellent (native iOS/Android)\nNeeds app\n\n\n\nUse IPSec when: Performance matters, native clients needed, LAN-to-LAN.\nUse OpenVPN when: Firewall restrictions (masquerade as HTTPS), simpler setup.\n\n\nIPSec vs WireGuard\n\n\n\nFeature\nIPSec\nWireGuard\n\n\n\n\nComplexity\nComplex\nSimple\n\n\nCode Size\n400K+ lines\n4K lines\n\n\nPerformance\nFast\nFaster\n\n\nSetup\nMany knobs\nMinimal config\n\n\nCompatibility\nEverywhere\nNewer\n\n\nRoaming\nGood (IKEv2)\nExcellent\n\n\n\nUse IPSec when: Need enterprise features (certificate-based, EAP auth), must use native clients.\nUse WireGuard when: Simplicity and performance matter most, modern OS/kernel."
  },
  {
    "objectID": "ipsec_primer.html#common-use-cases",
    "href": "ipsec_primer.html#common-use-cases",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "19. Common Use Cases",
    "text": "19. Common Use Cases\n\n1. Site-to-Site VPN\nScenario: Connect two office networks.\nMode: Tunnel (gateway-to-gateway) Auth: Certificates or PSK Best for: 24/7 persistent tunnels\n\n\n2. Road Warrior VPN\nScenario: Remote employees accessing corporate network.\nMode: Tunnel (client-to-gateway) Auth: Certificates + EAP (username/password) Features: IP pool, split tunneling, DNS push\n\n\n3. Host-to-Host\nScenario: Secure communication between two servers.\nMode: Transport Auth: Certificates Best for: Database server to app server, microservices\n\n\n4. Cloud VPN\nScenario: Connect on-prem to AWS/Azure/GCP.\nProviders: - AWS VPN: IKEv1/v2, route-based or policy-based - Azure VPN Gateway: IKEv2 (v1 deprecated) - GCP Cloud VPN: IKEv2, HA VPN\nGotchas: Cloud provider-specific quirks, BGP for dynamic routing"
  },
  {
    "objectID": "ipsec_primer.html#configuration-examples-by-platform",
    "href": "ipsec_primer.html#configuration-examples-by-platform",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "20. Configuration Examples by Platform",
    "text": "20. Configuration Examples by Platform\n\nLinux (strongSwan)\nAlready covered above. Most flexible, widely used.\n\n\nFreeBSD (strongSwan or racoon)\nstrongSwan: Same as Linux racoon (legacy):\n# /usr/local/etc/racoon/racoon.conf\npath pre_shared_key \"/usr/local/etc/racoon/psk.txt\";\n\nremote 203.0.113.2 {\n    exchange_mode main;\n    proposal {\n        encryption_algorithm aes 256;\n        hash_algorithm sha256;\n        authentication_method pre_shared_key;\n        dh_group modp2048;\n    }\n}\n\nsainfo address 10.1.0.0/24 any address 10.2.0.0/24 any {\n    pfs_group modp2048;\n    encryption_algorithm aes 256;\n    authentication_algorithm hmac_sha256;\n    compression_algorithm deflate;\n}\n\n\nCisco IOS\ncrypto isakmp policy 10\n encryption aes 256\n hash sha256\n authentication pre-share\n group 14\n\ncrypto isakmp key MySecretKey address 203.0.113.2\n\ncrypto ipsec transform-set MYSET esp-aes 256 esp-sha256-hmac\n mode tunnel\n\ncrypto map MYMAP 10 ipsec-isakmp\n set peer 203.0.113.2\n set transform-set MYSET\n match address 100\n\ninterface GigabitEthernet0/0\n crypto map MYMAP\n\naccess-list 100 permit ip 10.1.0.0 0.0.0.255 10.2.0.0 0.0.0.255\n\n\nWindows (Built-in)\nPowerShell:\nAdd-VpnConnection -Name \"Corporate\" `\n    -ServerAddress \"vpn.company.com\" `\n    -TunnelType IKEv2 `\n    -AuthenticationMethod EAP `\n    -EncryptionLevel Maximum\n\nSet-VpnConnectionIPsecConfiguration -ConnectionName \"Corporate\" `\n    -AuthenticationTransformConstants SHA256128 `\n    -CipherTransformConstants AES256 `\n    -EncryptionMethod AES256 `\n    -IntegrityCheckMethod SHA256 `\n    -DHGroup Group14 `\n    -PfsGroup PFS2048"
  },
  {
    "objectID": "ipsec_primer.html#advanced-topics-brief-overview",
    "href": "ipsec_primer.html#advanced-topics-brief-overview",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "21. Advanced Topics (Brief Overview)",
    "text": "21. Advanced Topics (Brief Overview)\n\nIKEv2 Redirect\nServer can redirect client to different gateway (load balancing, maintenance).\n\n\nMultiple SAs (Child SAs)\nOne IKE SA can have multiple IPSec SAs (different traffic selectors).\n\n\nTraffic Selectors\nFine-grained control over which traffic uses which SA.\n# Site A -&gt; Site B web servers\nleftsubnet=10.1.0.0/24[tcp/1024-65535]\nrightsubnet=10.2.0.0/24[tcp/80]\n\n\nXFRM (Linux)\nLinux kernel‚Äôs IPSec stack. Controlled via ip xfrm commands.\nSupports: - Route-based VPN (VTI - Virtual Tunnel Interface) - Policy-based VPN (traditional)\n\n\nVTI (Virtual Tunnel Interface)\nCreates a virtual interface for IPSec tunnel (like OpenVPN‚Äôs tun).\nBenefits: - Easier routing - Works with dynamic routing (OSPF, BGP) - Simpler firewall rules\nip tunnel add vti0 mode vti local 203.0.113.1 remote 203.0.113.2 key 42\nip link set vti0 up\nip addr add 169.254.0.1/30 dev vti0\nip route add 10.2.0.0/24 dev vti0"
  },
  {
    "objectID": "ipsec_primer.html#debugging-deep-dive",
    "href": "ipsec_primer.html#debugging-deep-dive",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "22. Debugging Deep Dive",
    "text": "22. Debugging Deep Dive\n\nPacket Flow\nOutbound:\n1. Application sends packet\n2. Routing: Should this go through IPSec?\n3. SPD lookup: Match policy?\n4. SAD lookup: Find SA\n5. Encrypt with ESP\n6. Add ESP header\n7. Transmit\n\nInbound:\n1. Receive ESP packet\n2. Extract SPI from ESP header\n3. SAD lookup by SPI\n4. Decrypt and verify\n5. Check replay protection\n6. Remove ESP header\n7. Deliver to application\n\n\nCommon Error Messages\n‚Äúno matching SA‚Äù - Proposal mismatch (algorithms don‚Äôt match) - Fix: Use same proposals on both sides\n‚Äúauthentication failed‚Äù - PSK mismatch - Certificate validation failed (expired, wrong CA)\n‚Äúno policy found‚Äù - SPD not configured - Traffic selector mismatch\n‚Äúinvalid ID‚Äù - leftid/rightid mismatch - Certificate CN doesn‚Äôt match expected ID\n\n\nLog Analysis\nEnable verbose logging:\n# strongSwan\nconfig setup\n    charondebug=\"ike 2, knl 2, cfg 2, net 2\"\nLook for: - Proposal mismatch: Different algorithms - AUTH_FAILED: Wrong PSK or certificate - TS_UNACCEPTABLE: Traffic selector mismatch"
  },
  {
    "objectID": "ipsec_primer.html#quick-reference",
    "href": "ipsec_primer.html#quick-reference",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "23. Quick Reference",
    "text": "23. Quick Reference\n\nPorts and Protocols\n\nUDP 500: IKE (Phase 1)\nUDP 4500: NAT-T (IKE + ESP encapsulated)\nProtocol 50: ESP (data plane)\nProtocol 51: AH (data plane, rarely used)\n\n\n\nRecommended Configuration (2026)\n# Modern, secure, fast\nconn modern\n    keyexchange=ikev2\n    ike=aes256gcm16-sha256-modp2048!\n    esp=aes256gcm16-modp2048!\n    ikelifetime=28800s\n    lifetime=3600s\n    dpdaction=restart\n    dpddelay=30s\n    authby=pubkey\n\n\nCommand Cheat Sheet\n# strongSwan\nipsec start/stop/restart\nipsec up &lt;conn&gt;\nipsec down &lt;conn&gt;\nipsec status\nipsec statusall\n\n# Linux XFRM\nip xfrm state [add|del|list]\nip xfrm policy [add|del|list]\n\n# Statistics\nip -s xfrm state\nipsec statusall | grep bytes\n\n# Certificates\nipsec listcerts\nipsec listcacerts\nopenssl x509 -in cert.pem -text -noout"
  },
  {
    "objectID": "ipsec_primer.html#key-takeaways",
    "href": "ipsec_primer.html#key-takeaways",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "24. Key Takeaways",
    "text": "24. Key Takeaways\n\nESP in Tunnel Mode: What you‚Äôll use 99% of the time for VPNs.\nIKEv2 &gt; IKEv1: Always use IKEv2 unless forced to use v1.\nAES-GCM: Modern, fast, secure. Combines encryption + authentication.\nPFS is Essential: Always include DH group in ESP proposal.\nCertificates &gt; PSK: Scale better, more secure.\nNAT-T is Automatic: IKEv2 detects NAT and enables NAT-T.\nDPD Keeps Tunnels Alive: Essential for detecting failures.\nTwo Databases: SPD (when to use IPSec) and SAD (how to encrypt).\nMTU Matters: IPSec adds overhead, reduce TCP MSS or increase MTU.\nDebug with Logs: Enable verbose logging, watch for proposal mismatches."
  },
  {
    "objectID": "ipsec_primer.html#next-steps",
    "href": "ipsec_primer.html#next-steps",
    "title": "IPSec Primer: Secure IP Communications",
    "section": "25. Next Steps",
    "text": "25. Next Steps\nAfter This Primer: - Hands-on: Set up a site-to-site VPN between two VMs - PKI: Learn certificate management (OpenSSL, easy-rsa) - Advanced: VTI, route-based VPNs, BGP over IPSec - Cloud: AWS VPN, Azure VPN Gateway, GCP Cloud VPN - Alternatives: Compare with WireGuard, OpenVPN - Performance: Tuning, hardware acceleration, crypto benchmarks\nResources: - RFC 4301: IPSec Architecture - RFC 7296: IKEv2 - strongSwan documentation: https://docs.strongswan.org/ - LibreSwan: https://libreswan.org/\n\nYou now know ~80% of IPSec. The rest is practice, troubleshooting real-world tunnels, and dealing with vendor quirks. Good luck! üîê"
  },
  {
    "objectID": "hdd_tco_summary.html",
    "href": "hdd_tco_summary.html",
    "title": "HDD comparison and 5-year TCO",
    "section": "",
    "text": "Compare three enterprise nearline HDDs for a storage cluster.\nRequirement: 5 PB (5,000 TB decimal) raw capacity already includes replication/EC overhead.\nStorage servers: 24 bays/server, ‚Çπ8‚Äì9L capex per server.\nElectricity: ‚Çπ17/kWh, 24√ó7, 5 years.\nTCO includes: drive capex + server capex + electricity (drive idle + server base idle).\nElectricity model uses vendor datasheet idle watts for drives; server base idle is an explicit assumption."
  },
  {
    "objectID": "hdd_tco_summary.html#context",
    "href": "hdd_tco_summary.html#context",
    "title": "HDD comparison and 5-year TCO",
    "section": "",
    "text": "Compare three enterprise nearline HDDs for a storage cluster.\nRequirement: 5 PB (5,000 TB decimal) raw capacity already includes replication/EC overhead.\nStorage servers: 24 bays/server, ‚Çπ8‚Äì9L capex per server.\nElectricity: ‚Çπ17/kWh, 24√ó7, 5 years.\nTCO includes: drive capex + server capex + electricity (drive idle + server base idle).\nElectricity model uses vendor datasheet idle watts for drives; server base idle is an explicit assumption."
  },
  {
    "objectID": "hdd_tco_summary.html#dc-grade-assessment-short",
    "href": "hdd_tco_summary.html#dc-grade-assessment-short",
    "title": "HDD comparison and 5-year TCO",
    "section": "DC-grade assessment (short)",
    "text": "DC-grade assessment (short)\n\nAll three are data-center/enterprise nearline SKUs on-paper: 24√ó7 duty class, 5-year warranty, MTBF/AFR class typical of DC drives.\nDifferences are mainly capacity per drive (18TB vs 24TB) and minor interface/power/feature details."
  },
  {
    "objectID": "hdd_tco_summary.html#inputs-used",
    "href": "hdd_tco_summary.html#inputs-used",
    "title": "HDD comparison and 5-year TCO",
    "section": "Inputs used",
    "text": "Inputs used\n\nTime horizon: 5 years (hours = 43,800)\nServer base idle (excluding disks): 400W/server (assumption; see sensitivity)\nDrive idle watts (from datasheets):\n\nSeagate Exos X24 ST24000NM007H: 6.5W idle; https://www.seagate.com/content/dam/seagate/en/content-fragments/products/datasheets/exos-x24/exos-x24-DS2080-2307US-en_US.pdf\nWD Ultrastar DC HC590 24TB (SKU 0F59373): 5.9W idle; https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/data-center-drives/ultrastar-dc-hc500-series/data-sheet-ultrastar-dc-hc590.pdf\nSeagate Exos X20 ST18000NM000D: 5.8W idle; https://www.seagate.com/files/www-content/datasheets/pdfs/exos-x20-channel-DS2080-2111GB-en_EM.pdf"
  },
  {
    "objectID": "hdd_tco_summary.html#drive-counts-and-server-counts-to-reach-5000-tb",
    "href": "hdd_tco_summary.html#drive-counts-and-server-counts-to-reach-5000-tb",
    "title": "HDD comparison and 5-year TCO",
    "section": "Drive counts and server counts to reach ‚â•5,000 TB",
    "text": "Drive counts and server counts to reach ‚â•5,000 TB\n\nFormulae:\n\ndrives = ceil(5000 / TB_per_drive)\nservers = ceil(drives / 24)"
  },
  {
    "objectID": "hdd_tco_summary.html#year-cost-model",
    "href": "hdd_tco_summary.html#year-cost-model",
    "title": "HDD comparison and 5-year TCO",
    "section": "5-year cost model",
    "text": "5-year cost model\n\nElectricity:\n\nkWh = (Watts/1000) * hours\npower_cost = kWh * ‚Çπ17\n\n5-year TCO range (server capex ‚Çπ8‚Äì9L):\n\nTCO = drive_capex + server_capex + drive_power_cost + server_power_cost"
  },
  {
    "objectID": "hdd_tco_summary.html#results-5-pb-raw",
    "href": "hdd_tco_summary.html#results-5-pb-raw",
    "title": "HDD comparison and 5-year TCO",
    "section": "Results (5 PB raw)",
    "text": "Results (5 PB raw)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDrive\nTB/drive\nDrives\nServers (24-bay)\nDrive CAPEX\nServer CAPEX\n5y drive power\n5y server power (@400W)\n5y TCO\n‚Çπ/TB (drive-only)\n\n\n\n\nSeagate Exos X24 ST24000NM007H\n24\n209\n9\n97.19L\n72.00L‚Äì81.00L\n10.12L\n26.81L\n206.11L‚Äì215.11L\n1937.5\n\n\nWD Ultrastar DC HC590 24TB (SKU 0F59373)\n24\n209\n9\n96.56L\n72.00L‚Äì81.00L\n9.18L\n26.81L\n204.55L‚Äì213.55L\n1925.0\n\n\nSeagate Exos X20 ST18000NM000D\n18\n278\n12\n80.62L\n96.00L‚Äì108.00L\n12.01L\n35.74L\n224.37L‚Äì236.37L\n1611.11"
  },
  {
    "objectID": "hdd_tco_summary.html#findings",
    "href": "hdd_tco_summary.html#findings",
    "title": "HDD comparison and 5-year TCO",
    "section": "Findings",
    "text": "Findings\n\nArchitecture dominates: with ‚Çπ8‚Äì9L per 24-bay server, the 18TB option requires 12 servers vs 9 servers for 24TB drives.\nThat extra server capex (and base power) outweighs the 18TB drive‚Äôs lower ‚Çπ/TB.\nBest 5-year value (your constraints): WD Ultrastar DC HC590 24TB.\nThe two 24TB options are close; HC590 wins slightly on your pricing and lower drive idle watts."
  },
  {
    "objectID": "hdd_tco_summary.html#sensitivity-server-idle-power",
    "href": "hdd_tco_summary.html#sensitivity-server-idle-power",
    "title": "HDD comparison and 5-year TCO",
    "section": "Sensitivity (server idle power)",
    "text": "Sensitivity (server idle power)\n\nExtra electricity per +100W per server over 5 years: ‚Çπ74,460 (~0.74L).\nFor 9 servers: +100W/server adds ‚Çπ670,140 (~6.70L).\nFor 12 servers: +100W/server adds ‚Çπ893,520 (~8.94L).\nIf your servers idle significantly above 400W, the penalty for needing more servers increases, which further favors 24TB drives."
  },
  {
    "objectID": "hdd_tco_summary.html#what-this-tco-excludes-important",
    "href": "hdd_tco_summary.html#what-this-tco-excludes-important",
    "title": "HDD comparison and 5-year TCO",
    "section": "What this TCO excludes (important)",
    "text": "What this TCO excludes (important)\n\nCooling overhead (PUE), rack space cost, networking/HBA costs, spares inventory, and operational labor.\nIf you provide measured wall power per storage server (idle) with disks installed and any PUE target, the power part can be tightened."
  },
  {
    "objectID": "hdd_tco_summary.html#datasheet-links",
    "href": "hdd_tco_summary.html#datasheet-links",
    "title": "HDD comparison and 5-year TCO",
    "section": "Datasheet links",
    "text": "Datasheet links\n\nSeagate Exos X24 ST24000NM007H: https://www.seagate.com/content/dam/seagate/en/content-fragments/products/datasheets/exos-x24/exos-x24-DS2080-2307US-en_US.pdf\nWD Ultrastar DC HC590 24TB (SKU 0F59373): https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/data-center-drives/ultrastar-dc-hc500-series/data-sheet-ultrastar-dc-hc590.pdf\nSeagate Exos X20 ST18000NM000D: https://www.seagate.com/files/www-content/datasheets/pdfs/exos-x20-channel-DS2080-2111GB-en_EM.pdf"
  },
  {
    "objectID": "ampereone_m_vs_amd_epyc.html",
    "href": "ampereone_m_vs_amd_epyc.html",
    "title": "AmpereOne M vs AMD EPYC 9554/9654",
    "section": "",
    "text": "AmpereOne M product brief: https://amperecomputing.com/briefs/ampereone-m-product-brief\nGIGABYTE R1A3-T40-AAV1 (your link may geo-block; this mirror usually works): https://www.gigabyte.com/il/Enterprise/Rack-Server/R1A3-T40-AAV1\nAMD EPYC 9004 series datasheet (model table includes 9554/9654): https://www.amd.com/content/dam/amd/en/documents/epyc-business-docs/datasheets/amd-epyc-9004-series-processors-datasheet.pdf"
  },
  {
    "objectID": "ampereone_m_vs_amd_epyc.html#sources-used",
    "href": "ampereone_m_vs_amd_epyc.html#sources-used",
    "title": "AmpereOne M vs AMD EPYC 9554/9654",
    "section": "",
    "text": "AmpereOne M product brief: https://amperecomputing.com/briefs/ampereone-m-product-brief\nGIGABYTE R1A3-T40-AAV1 (your link may geo-block; this mirror usually works): https://www.gigabyte.com/il/Enterprise/Rack-Server/R1A3-T40-AAV1\nAMD EPYC 9004 series datasheet (model table includes 9554/9654): https://www.amd.com/content/dam/amd/en/documents/epyc-business-docs/datasheets/amd-epyc-9004-series-processors-datasheet.pdf"
  },
  {
    "objectID": "ampereone_m_vs_amd_epyc.html#executive-summary-what-changes-vs-your-current-epyc-nodes",
    "href": "ampereone_m_vs_amd_epyc.html#executive-summary-what-changes-vs-your-current-epyc-nodes",
    "title": "AmpereOne M vs AMD EPYC 9554/9654",
    "section": "Executive summary (what changes vs your current EPYC nodes)",
    "text": "Executive summary (what changes vs your current EPYC nodes)\nYou‚Äôre comparing two very different approaches to ‚Äúcore dense‚Äù:\n\nAMD EPYC 9554 / 9654 (x86_64 + SMT): fewer cores than Ampere‚Äôs top-end SKUs, but 2 threads/core, strong per-core performance, and more I/O (128 PCIe Gen5 lanes).\nAmpereOne M (Armv8.6+, single-threaded cores): many single-threaded cores with 12-channel DDR5-5600, and a platform story optimized for predictable, scale-out throughput ‚Äî but fewer I/O lanes (96 PCIe Gen5) and an Arm software/ops compatibility tax if your stack isn‚Äôt already Arm-friendly."
  },
  {
    "objectID": "ampereone_m_vs_amd_epyc.html#at-a-glance-specs-socket-level",
    "href": "ampereone_m_vs_amd_epyc.html#at-a-glance-specs-socket-level",
    "title": "AmpereOne M vs AMD EPYC 9554/9654",
    "section": "At-a-glance specs (socket-level)",
    "text": "At-a-glance specs (socket-level)\n\n\n\n\n\n\n\n\n\nItem\nAMD EPYC 9554\nAMD EPYC 9654\nAmpereOne M (family)\n\n\n\n\nISA / platform\nx86_64 (SP5)\nx86_64 (SP5)\nArmv8.6+ (SoC)\n\n\nCores / threads\n64 / 128\n96 / 192\n96‚Äì192 / 96‚Äì192 (single-thread)\n\n\nBase / boost (GHz)\n3.10 / 3.75\n2.40 / 3.70\nModel-dependent (2.6‚Äì3.6 shown)\n\n\nDefault / usage power\n360W (default TDP)\n360W (default TDP)\n239‚Äì348W ‚ÄúUsage Power*‚Äù by model (brief)\n\n\nMemory channels\n12\n12\n12\n\n\nMax DDR5 speed (1DPC)\n4800 MT/s\n4800 MT/s\n5600 MT/s (brief)\n\n\nPeak memory bandwidth\n460.8 GB/s (datasheet)\n460.8 GB/s (datasheet)\n~537.6 GB/s (12 √ó 5600 MT/s √ó 8 B; theoretical)\n\n\nPCIe Gen5 lanes\n128\n128\n96 (brief)"
  },
  {
    "objectID": "ampereone_m_vs_amd_epyc.html#pros-cons-amd-epyc-vs-ampereone-m",
    "href": "ampereone_m_vs_amd_epyc.html#pros-cons-amd-epyc-vs-ampereone-m",
    "title": "AmpereOne M vs AMD EPYC 9554/9654",
    "section": "Pros / cons: AMD EPYC vs AmpereOne M",
    "text": "Pros / cons: AMD EPYC vs AmpereOne M\n\nAMD EPYC (9554/9654 class)\nPros\n\nSoftware compatibility: x86_64 ‚Äújust works‚Äù for the broadest set of enterprise software, drivers, agents, and proprietary stacks.\nHigh thread count with SMT: if your workload benefits from SMT, you get 2√ó threads/core.\nI/O headroom: 128 lanes of PCIe Gen5 per socket is hard to beat when you need many GPUs / NICs / NVMe.\nMature tuning + observability: generally easier to find established guidance for BIOS, NUMA, perf counters, and vendor ecosystem tooling.\n\nCons\n\nHigher platform power for a given throughput-per-rack goal if you‚Äôre ultimately limited by memory bandwidth efficiency or ‚Äúscale-out core density‚Äù.\nLicense cost sensitivity for software priced per core / per socket can dominate your economics (depends on your stack).\n\n\n\nAmpereOne M\nPros\n\nCore density: 96‚Äì192 single-threaded cores per socket can increase throughput-per-rack for workloads that scale well with more independent threads (stateless services, batchy inference, analytics pipelines).\nMemory bandwidth focus: 12-channel DDR5-5600 (brief) is a clear design point for bandwidth-sensitive throughput workloads.\nPredictability: single-threaded cores and the ‚Äúcloud native‚Äù design goal can help with performance consistency (still validate on your stack).\n\nCons\n\nArm migration/ops tax: base images, agents, proprietary libs, and vendor support may lag x86_64 depending on your environment.\nVector ISA / codegen differences: CPU instruction set and library ecosystem differ; some workloads need re-tuning or don‚Äôt have comparable optimized kernels.\nLess PCIe lane budget: 96 PCIe Gen5 lanes (brief) can be a real constraint for GPU/NVMe/NIC-heavy designs."
  },
  {
    "objectID": "ampereone_m_vs_amd_epyc.html#where-to-run-amd-vs-where-to-run-arm-practical-placement-guide",
    "href": "ampereone_m_vs_amd_epyc.html#where-to-run-amd-vs-where-to-run-arm-practical-placement-guide",
    "title": "AmpereOne M vs AMD EPYC 9554/9654",
    "section": "Where to run AMD vs where to run Arm (practical placement guide)",
    "text": "Where to run AMD vs where to run Arm (practical placement guide)\nThink of Arm (AmpereOne M) as a throughput-per-watt / scale-out play, and AMD EPYC as the lowest-risk default for compatibility + per-thread performance + I/O-heavy nodes.\n\nRun on AMD EPYC (x86_64) when‚Ä¶\n\nYou can‚Äôt fully support Arm in prod yet: any ‚Äúmust have‚Äù component is x86-only (vendor app, security agent, backup agent, monitoring, kernel module, proprietary driver, etc.).\nSingle-thread and tail latency dominate: workloads with strict p95/p99 latency, high per-request CPU, or limited parallelism tend to prefer strong per-core performance.\nYour nodes are I/O-lane constrained: you need lots of PCIe devices per socket (GPUs, multiple high-speed NICs, many NVMe drives, HBAs/DPUs). EPYC‚Äôs 128 PCIe Gen5 lanes is a big advantage.\nYou rely on x86-specific acceleration or tuning: compiled kernels, hand-tuned libraries, or toolchains that assume x86 (common in HPC/EDA/legacy stacks).\nSoftware licensing penalizes high core counts: if your critical software is licensed per core, a 160‚Äì192-core Arm CPU can be economically worse even if it‚Äôs efficient.\n\n\n\nRun on AmpereOne M (Arm) when‚Ä¶\n\nYour stack is ‚Äúrebuildable‚Äù: you can build and ship linux/arm64 artifacts (or use multi-arch container images) for the app and its dependencies.\nThroughput scales with more independent threads: stateless services, web/API tiers, batch workers, message consumers, ETL steps, and many ‚Äúembarrassingly parallel‚Äù jobs.\nYou‚Äôre memory bandwidth sensitive: AmpereOne M is explicitly positioned around 12-channel DDR5-5600 and core density; that‚Äôs often a good fit when you‚Äôre bottlenecked on memory throughput rather than per-thread IPC.\nPower/rack density is a primary constraint: if you‚Äôre hitting rack power limits before space limits, Arm‚Äôs efficiency goals can translate into real capacity gains (validate with your workload).\n\n\n\nTypical ‚Äúgood fits‚Äù (starting assumptions)\n\n\n\n\n\n\n\n\n\nWorkload area\nDefault pick\nWhen Arm usually makes sense\nWhen AMD usually stays better\n\n\n\n\nWeb / API stateless services\nArm candidate\nGo/Java/Node services, containerized, easy CI builds, horizontal scaling\nVery latency-sensitive endpoints or hard-to-rebuild legacy deps\n\n\nBatch workers / queues\nArm candidate\nHigh parallelism, lots of concurrent jobs, predictable CPU work\nJobs with specialized x86-only libraries or heavy per-thread performance needs\n\n\nDatabases / stateful data\nAMD default\nOpen-source DBs you can validate thoroughly; read-heavy fleets; cost/power pressure\nVendor appliances, x86-tuned deployments, extreme p99 requirements, or ‚Äúone big box‚Äù scaling\n\n\nCPU-only inference\ndepends\nMany concurrent small models / pipelines, throughput-oriented serving\nIf per-request latency is strict and model kernels are x86-optimized in your stack\n\n\nGPU-heavy training/inference\nAMD default (for CPU host)\nOnly if the exact GPU + driver + orchestration stack is proven on Arm\nWhen you need maximum PCIe lanes and broadest ecosystem support\n\n\nVirtualization platforms\nAMD default\nIf you run KVM and have full tool/agent support on Arm\nIf you rely on VMware or x86-only guest/management tooling\n\n\n\n\n\nTwo easy deployment patterns\n\nSeparate node pools / fleets:\n\namd64 pool for ‚Äúeverything works‚Äù workloads.\narm64 pool for explicitly qualified workloads.\n\nKubernetes: schedule by architecture:\n\nBuild multi-arch images and use node selectors/affinity (e.g., kubernetes.io/arch=arm64)."
  },
  {
    "objectID": "ampereone_m_vs_amd_epyc.html#a-simple-decision-tree-for-amd-or-arm",
    "href": "ampereone_m_vs_amd_epyc.html#a-simple-decision-tree-for-amd-or-arm",
    "title": "AmpereOne M vs AMD EPYC 9554/9654",
    "section": "A simple decision tree for ‚ÄúAMD or Arm?‚Äù",
    "text": "A simple decision tree for ‚ÄúAMD or Arm?‚Äù\n\nCan I run it on Arm without heroics? (build + deps + agents + drivers)\n\nNo ‚Üí AMD\n\nIs it I/O-lane heavy? (lots of PCIe devices per node)\n\nYes ‚Üí AMD\n\nIs single-thread / p99 critical and hard to parallelize?\n\nYes ‚Üí AMD\n\nOtherwise, does it scale with many independent threads and is power/cost a concern?\n\nYes ‚Üí Arm candidate, then validate perf/W and perf/$ in a POC"
  },
  {
    "objectID": "ampereone_m_vs_amd_epyc.html#architecture-basics-x86_64-amd-epyc-vs-arm64-ampereone-m",
    "href": "ampereone_m_vs_amd_epyc.html#architecture-basics-x86_64-amd-epyc-vs-arm64-ampereone-m",
    "title": "AmpereOne M vs AMD EPYC 9554/9654",
    "section": "Architecture basics: x86_64 (AMD EPYC) vs Arm64 (AmpereOne M)",
    "text": "Architecture basics: x86_64 (AMD EPYC) vs Arm64 (AmpereOne M)\nAt a high level, both are modern 64-bit server CPUs running Linux, but they differ in the instruction set, ecosystem assumptions, and some performance/optimization ‚Äúdefaults‚Äù.\n\n1) Instruction set (ISA) and ABI\n\nAMD EPYC runs x86_64 binaries (ELF x86-64).\nAmpereOne M runs AArch64 / arm64 binaries (ELF aarch64).\n\nThis is the root cause of most ‚Äúdoesn‚Äôt run on Arm‚Äù issues: a prebuilt program compiled for x86_64 cannot execute on Arm64 without recompilation (or emulation, which is usually not acceptable for production performance).\n\n\n2) SIMD / vector extensions (where hidden incompatibilities show up)\nMany ‚ÄúCPU-intensive‚Äù libraries rely on vector instruction sets.\n\nx86 often leans on SSE/AVX/AVX2/AVX-512.\nArm commonly uses NEON (and sometimes SVE/SVE2 depending on CPU and build targets).\n\nIf an application (or a dependency) ships x86-only optimized code paths (e.g., AVX-512) and doesn‚Äôt provide Arm equivalents, you can see: - ‚ÄúIllegal instruction‚Äù crashes (if runtime dispatch is wrong), - or it compiles/runs but performs much worse (falls back to scalar code).\n\n\n3) Threads and scheduling assumptions\n\nYour EPYC nodes use SMT (2 threads/core), so software often sees ‚Äúmore CPUs‚Äù than physical cores.\nAmpereOne M cores are positioned as single-threaded cores (1 thread/core).\n\nApplications that were tuned assuming SMT behavior (thread pool sizing, CPU pinning, latency isolation) may need re-tuning on Arm even if they are ‚Äúsupported‚Äù.\n\n\n4) Platform model differences\n\nEPYC is a classic server CPU platform (CPU + chipset/IOD, SP5 ecosystem).\nAmpereOne M is more SoC-like in how the platform is built and validated (still standard server components, but a different vendor ecosystem).\n\nPractically, this affects out-of-tree drivers, BIOS/firmware tooling, and vendor-provided management integrations."
  },
  {
    "objectID": "ampereone_m_vs_amd_epyc.html#what-kinds-of-applications-might-not-have-support-on-arm",
    "href": "ampereone_m_vs_amd_epyc.html#what-kinds-of-applications-might-not-have-support-on-arm",
    "title": "AmpereOne M vs AMD EPYC 9554/9654",
    "section": "What kinds of applications might not have support on Arm?",
    "text": "What kinds of applications might not have support on Arm?\nThe pattern is: anything delivered only as an x86_64 binary (or relying on x86-only kernel/user-space components).\n\n1) Closed-source / proprietary binaries\n\nCommercial software distributed as a single x86_64 build (no Arm download).\n‚ÄúAppliance-like‚Äù stacks where the vendor only certifies x86_64.\nLegacy enterprise software that embeds x86 native components.\n\n\n\n2) Kernel modules and low-level agents\nThese are common early blockers: - Endpoint/security agents (EDR), DLP, vulnerability scanners - Backup agents - Storage/network drivers, RDMA stacks, DPDK variants (depends), special NIC features - GPU/accelerator drivers and management tooling (often works on Arm in some combos, but don‚Äôt assume)\nIf the solution requires a kernel module, you need explicit Arm64 support for your kernel + distro combination.\n\n\n3) Language ecosystems with native extensions (it ‚Äúinstalls‚Äù until it doesn‚Äôt)\nEven when your application is ‚Äúportable‚Äù (Go/Java/Python/Node), its dependencies may include native code:\n\nPython: pip packages with native wheels may be missing manylinux_aarch64 wheels, forcing source builds (which may fail due to missing toolchains or incompatible C/ASM).\nNode.js: native addons (node-gyp) may lack arm64 prebuilds.\nJava/JVM: the JVM itself supports arm64 well, but JNI libraries might not.\nRust/C/C++: usually fine if you build from source, but some projects have x86-only assembly.\n\n\n\n4) Applications depending on x86-specific optimizations\nExamples: - Media/codec stacks tuned for x86 intrinsics only - Some HPC/EDA toolchains and proprietary numeric libraries - Any codebase with hand-written x86 assembly\n\n\n5) Virtualization and guest OS constraints\n\nIf you need to run x86_64 guests on the same host, Arm servers can‚Äôt do that natively.\nSome virtualization ecosystems (notably VMware) are effectively x86-only in common enterprise deployments."
  },
  {
    "objectID": "ampereone_m_vs_amd_epyc.html#fast-ways-to-detect-arm-readiness-before-you-buy-a-lot-of-servers",
    "href": "ampereone_m_vs_amd_epyc.html#fast-ways-to-detect-arm-readiness-before-you-buy-a-lot-of-servers",
    "title": "AmpereOne M vs AMD EPYC 9554/9654",
    "section": "Fast ways to detect Arm readiness (before you buy a lot of servers)",
    "text": "Fast ways to detect Arm readiness (before you buy a lot of servers)\n\nContainer images: do they publish linux/arm64?\n\ndocker manifest inspect &lt;image&gt;:&lt;tag&gt; | rg -n \\\"arm64|amd64\\\"\n\nLinux packages: do they ship aarch64/arm64 builds for your distro?\n\nDebian/Ubuntu: check arm64 availability in your repo + vendor repo.\nRHEL-like: check aarch64 RPM availability and kernel module support.\n\nYour own binaries: can you build and run CI for arm64?\n\nuname -m on the target (aarch64 vs x86_64)\nfile &lt;binary&gt; should show aarch64 for Arm targets."
  },
  {
    "objectID": "ampereone_m_vs_amd_epyc.html#equivalent-cpu-selection-how-to-map-epyc-95549654-ampereone-m",
    "href": "ampereone_m_vs_amd_epyc.html#equivalent-cpu-selection-how-to-map-epyc-95549654-ampereone-m",
    "title": "AmpereOne M vs AMD EPYC 9554/9654",
    "section": "‚ÄúEquivalent‚Äù CPU selection: how to map EPYC 9554/9654 ‚Üí AmpereOne M",
    "text": "‚ÄúEquivalent‚Äù CPU selection: how to map EPYC 9554/9654 ‚Üí AmpereOne M\nThere isn‚Äôt a single ‚Äúequivalent‚Äù, because AMD cores and Ampere cores are not interchangeable. Pick equivalence based on what you‚Äôre trying to preserve:\n\nThread budget equivalence (how many runnable software threads you want per node)\nPower envelope equivalence (stay within a rack/power budget per node)\nMemory bandwidth equivalence (channels √ó speed, plus workload memory behavior)\nI/O equivalence (PCIe lanes and slot topology)\nSingle-thread / tail-latency equivalence (p99 requirements)\n\n\nPractical mapping shortlist (starting point)\nUse this as a POC shortlist, not a final answer.\n\n\n\n\n\n\n\n\n\nIf you run today‚Ä¶\nWhat you likely value\nAmpereOne M candidates to try\nWhy these are ‚Äúclosest‚Äù\n\n\n\n\nEPYC 9554 (64C/128T, 360W)\nhigher per-core perf, moderate core count, still lots of threads\nA96-36M (96C @ 3.6, 331W), A144-33M (144C @ 3.3, 334W), A144-26M (144C @ 2.6, 239W)\nA96-36M is the ‚Äúfewer cores, higher freq‚Äù end; A144 variants test whether more cores improves throughput under similar or lower power\n\n\nEPYC 9654 (96C/192T, 360W)\nhigh thread count / throughput per node\nA192-32M (192C @ 3.2, 348W), A160-28M (160C @ 2.8, 262W), A192-26M (192C @ 2.6, 278W)\nA192-32M matches the thread budget (192) at similar power; A160/A192-26M are ‚Äúefficiency-first‚Äù comparators\n\n\n\n\n\nOne hard constraint: PCIe lane budget\nIf your current EPYC nodes are built around lane-heavy designs (many NVMe drives, multiple NICs, GPUs, DPUs), treat 128 lanes (EPYC) vs 96 lanes (AmpereOne M) as a first-order design constraint. It can change the entire server bill of materials more than the CPU choice itself."
  },
  {
    "objectID": "ampereone_m_vs_amd_epyc.html#gigabyte-r1a3-t40-aav1-notes-ampereone-m-platform",
    "href": "ampereone_m_vs_amd_epyc.html#gigabyte-r1a3-t40-aav1-notes-ampereone-m-platform",
    "title": "AmpereOne M vs AMD EPYC 9554/9654",
    "section": "GIGABYTE R1A3-T40-AAV1 notes (AmpereOne M platform)",
    "text": "GIGABYTE R1A3-T40-AAV1 notes (AmpereOne M platform)\nFrom the vendor spec page, this platform is a 1U, single-socket AmpereOne M server with:\n\n12 DDR5 RDIMM slots (12-channel per CPU)\n4 front hot-swap bays (Gen5 NVMe / SATA / SAS-4 support)\n2 √ó FHHL PCIe Gen5 x16 slots + 2 √ó OCP NIC 3.0 PCIe Gen5 x16 slots\nRedundant power supplies (config shown as Titanium-class)\n\nThis makes it a reasonable evaluation chassis for NIC + accelerator + limited local storage designs; less ideal if you need lots of front NVMe bays in 1U."
  },
  {
    "objectID": "ampereone_m_vs_amd_epyc.html#recommendation-a-minimal-decision-oriented-poc",
    "href": "ampereone_m_vs_amd_epyc.html#recommendation-a-minimal-decision-oriented-poc",
    "title": "AmpereOne M vs AMD EPYC 9554/9654",
    "section": "Recommendation: a minimal, decision-oriented POC",
    "text": "Recommendation: a minimal, decision-oriented POC\n\nPick one workload per ‚Äúshape‚Äù you run: (a) latency-sensitive service, (b) batch/throughput service, (c) memory-bandwidth-heavy job, (d) IO-heavy node.\nTest 2 Ampere SKUs per AMD SKU (from the shortlist) and keep memory config constant (same capacity per channel).\nCompare: throughput/socket, p99 latency, perf/W, and perf/$ (including any software/license deltas).\nFail fast on compatibility: image build, agents, monitoring, kernel/driver support, and any proprietary binaries."
  },
  {
    "objectID": "arista_switch_health_report.html",
    "href": "arista_switch_health_report.html",
    "title": "Arista Switch Health Report (DCS-7060CX-32S-R)",
    "section": "",
    "text": "This page summarizes findings from the health report file healthreport_Arista.txt."
  },
  {
    "objectID": "arista_switch_health_report.html#snapshot",
    "href": "arista_switch_health_report.html#snapshot",
    "title": "Arista Switch Health Report (DCS-7060CX-32S-R)",
    "section": "Snapshot",
    "text": "Snapshot\n\nReport timestamp: Sat Jan 31 09:41:47 UTC 2026\nModel: Arista DCS-7060CX-32S-R (HW v01.00, Mfg date 2016-04-21)\nEOS: 4.26.6M\nUptime at capture: ~20 minutes"
  },
  {
    "objectID": "arista_switch_health_report.html#overall-status",
    "href": "arista_switch_health_report.html#overall-status",
    "title": "Arista Switch Health Report (DCS-7060CX-32S-R)",
    "section": "Overall status",
    "text": "Overall status\nCooling, temperatures, and flash look healthy. The report shows PSU2 offline, but in this test setup that was expected because PSU2 was not connected to power (so the system was running without redundancy)."
  },
  {
    "objectID": "arista_switch_health_report.html#key-findings",
    "href": "arista_switch_health_report.html#key-findings",
    "title": "Arista Switch Health Report (DCS-7060CX-32S-R)",
    "section": "Key findings",
    "text": "Key findings\n\n\n\n\n\n\n\n\nArea\nStatus\nNotes\n\n\n\n\nCooling\nPass\nFans OK and stable; ambient 25¬∞C\n\n\nTemperature\nPass\nAll sensors below alert/critical thresholds\n\n\nPower supplies\nExpected (lab setup)\nPSU1 OK (~125.5W load); PSU2 shows ‚ÄúPower Loss Offline‚Äù when not connected\n\n\nModules/ASIC status\nScript false-fail\nshow module is not supported on this platform, so the report‚Äôs FAIL here is not a hardware fault by itself\n\n\nInterfaces\nN/A (bench state)\nAll ports show notconnect / Not Present (no optics/cables); Ma1 also down\n\n\nFlash\nPass\n/mnt/flash 63% used; writable"
  },
  {
    "objectID": "arista_switch_health_report.html#details",
    "href": "arista_switch_health_report.html#details",
    "title": "Arista Switch Health Report (DCS-7060CX-32S-R)",
    "section": "Details",
    "text": "Details\n\nPower (expected in this test setup)\nshow environment power indicates:\n\nPSU 1: Ok, drawing input current and supplying ~125.5W\nPSU 2: Power Loss Offline, 0.0W (expected when not connected)\n\nThis is fine for lab testing, but it removes redundancy and increases risk if PSU1 or its feed fails.\n\n\n‚ÄúModules are not reporting Active‚Äù (likely not real)\nThe report section ‚ÄúMODULE & ASIC STATUS‚Äù runs show module, but the output returns:\n\n‚ÄúUnavailable command (not supported on this hardware platform)‚Äù\n\nSo treat the report‚Äôs FAIL on that section as a limitation of the report script, not necessarily a device health issue."
  },
  {
    "objectID": "arista_switch_health_report.html#recommended-next-checks",
    "href": "arista_switch_health_report.html#recommended-next-checks",
    "title": "Arista Switch Health Report (DCS-7060CX-32S-R)",
    "section": "Recommended next checks",
    "text": "Recommended next checks\nTo restore redundancy, connect PSU2 to AC and confirm it transitions to Ok. If it still shows offline:\n\nReseat PSU2 and verify it‚Äôs the correct model for the chassis.\nSwap AC cable/outlet/circuit (or swap PSUs between slot 1 and slot 2 if you have a safe procedure).\nRe-run these commands and look for state changes:\n\nshow environment power\nshow logging | include PSU|Power|pwr|power-supply\nshow system environment cooling\nshow system environment temperature"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Research",
    "section": "",
    "text": "Notes, writeups, and summaries for personal research projects."
  },
  {
    "objectID": "index.html#documents",
    "href": "index.html#documents",
    "title": "Research",
    "section": "Documents",
    "text": "Documents\n\nHDD comparison and 5-year TCO\nAmpereOne M vs AMD EPYC 9554/9654\nArista switch health report (DCS-7060CX-32S-R)\nRust primer for C++/Java developers"
  },
  {
    "objectID": "kubernetes_primer.html",
    "href": "kubernetes_primer.html",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "",
    "text": "Goal: Get you to ~80% of Kubernetes, fast. Assumes you understand Docker/containers, basic networking, and Linux concepts. Skips: Custom operators, service mesh deep-dives, advanced RBAC patterns, multi-cluster federation."
  },
  {
    "objectID": "kubernetes_primer.html#what-is-kubernetes-and-why-does-it-exist",
    "href": "kubernetes_primer.html#what-is-kubernetes-and-why-does-it-exist",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "1. What is Kubernetes and Why Does It Exist?",
    "text": "1. What is Kubernetes and Why Does It Exist?\nThe Problem: You have containers. Maybe 5, maybe 500. How do you: - Deploy them across multiple machines? - Restart them when they crash? - Route traffic to them? - Update them without downtime? - Scale them up and down?\nThe Solution: Kubernetes (K8s) is a container orchestration platform. Think of it as an operating system for your datacenter.\nAnalogy: If Docker is like running a single process, Kubernetes is like systemd/supervisor but for a cluster of machines. You declare what you want (declarative), and K8s makes it happen (reconciliation loop)."
  },
  {
    "objectID": "kubernetes_primer.html#core-architecture-control-plane-vs-worker-nodes",
    "href": "kubernetes_primer.html#core-architecture-control-plane-vs-worker-nodes",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "2. Core Architecture: Control Plane vs Worker Nodes",
    "text": "2. Core Architecture: Control Plane vs Worker Nodes\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ      CONTROL PLANE (Master)         ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ\n‚îÇ  ‚îÇ API     ‚îÇ  ‚îÇ  etcd (database) ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ Server  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ\n‚îÇ  ‚îÇScheduler  ‚îÇ  ‚îÇ  Controllers   ‚îÇ ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n           ‚îÇ\n           ‚îÇ (manages)\n           ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ        WORKER NODES                  ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ\n‚îÇ  ‚îÇ  Node 1                     ‚îÇ    ‚îÇ\n‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ    ‚îÇ\n‚îÇ  ‚îÇ  ‚îÇ Pod  ‚îÇ  ‚îÇ Pod  ‚îÇ        ‚îÇ    ‚îÇ\n‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ    ‚îÇ\n‚îÇ  ‚îÇ  kubelet + container runtime‚îÇ    ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ\n‚îÇ  ... more nodes ...                 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\nControl Plane Components: - API Server: The front door. All communication goes through here (REST API). - etcd: Distributed key-value store. The source of truth for cluster state. - Scheduler: Decides which node runs which pod. - Controllers: Background processes that watch desired state vs actual state and reconcile.\nWorker Node Components: - kubelet: Agent on each node. Ensures containers are running. - kube-proxy: Network proxy. Routes traffic to pods. - Container Runtime: Docker, containerd, CRI-O, etc.\nMental Model: You tell the API server what you want. Controllers and scheduler figure out how to make it happen. Nodes do the actual work."
  },
  {
    "objectID": "kubernetes_primer.html#the-fundamental-building-block-pods",
    "href": "kubernetes_primer.html#the-fundamental-building-block-pods",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "3. The Fundamental Building Block: Pods",
    "text": "3. The Fundamental Building Block: Pods\nA Pod is the smallest deployable unit. It‚Äôs a wrapper around one or more containers that share: - Network namespace (same IP, can talk via localhost) - Storage volumes - Lifecycle\nAnalogy: A pod is like a logical host. Containers in a pod are like processes on the same machine.\napiVersion: v1\nkind: Pod\nmetadata:\n  name: my-app\nspec:\n  containers:\n  - name: nginx\n    image: nginx:1.21\n    ports:\n    - containerPort: 80\nKey Concepts: - Pods are ephemeral. They can die and be replaced. - Each pod gets its own IP address. - Containers in a pod share localhost (127.0.0.1).\nCommon Pattern: Main container + sidecar\nspec:\n  containers:\n  - name: app\n    image: myapp:v1\n  - name: log-shipper    # sidecar\n    image: fluent-bit\nWhen to use multiple containers in a pod: - Tightly coupled processes (e.g., app + log forwarder) - Helper containers that extend the main container\nDon‚Äôt deploy pods directly (usually). Use higher-level abstractions‚Ä¶"
  },
  {
    "objectID": "kubernetes_primer.html#deployments-managing-replicas-and-updates",
    "href": "kubernetes_primer.html#deployments-managing-replicas-and-updates",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "4. Deployments: Managing Replicas and Updates",
    "text": "4. Deployments: Managing Replicas and Updates\nDeployment = Pod template + replica count + update strategy\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-app\nspec:\n  replicas: 3                    # run 3 copies\n  selector:\n    matchLabels:\n      app: web\n  template:                      # pod template\n    metadata:\n      labels:\n        app: web\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.21\n        ports:\n        - containerPort: 80\nWhat it does: - Ensures 3 pods are always running - If a pod crashes, creates a new one - Handles rolling updates\nRolling Update:\nkubectl set image deployment/web-app nginx=nginx:1.22\nK8s will: 1. Create new pods with new image 2. Wait for them to be ready 3. Terminate old pods 4. No downtime!\nRollback:\nkubectl rollout undo deployment/web-app\nAnalogy: Deployment is like systemd + auto-restart + zero-downtime deploy built-in."
  },
  {
    "objectID": "kubernetes_primer.html#services-stable-networking-for-ephemeral-pods",
    "href": "kubernetes_primer.html#services-stable-networking-for-ephemeral-pods",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "5. Services: Stable Networking for Ephemeral Pods",
    "text": "5. Services: Stable Networking for Ephemeral Pods\nProblem: Pods are ephemeral. Their IPs change. How do you connect to them?\nSolution: A Service is a stable virtual IP + DNS name that load-balances to a set of pods.\n\nClusterIP (default)\nInternal load balancer. Only accessible within the cluster.\napiVersion: v1\nkind: Service\nmetadata:\n  name: web-service\nspec:\n  type: ClusterIP\n  selector:\n    app: web              # targets pods with label app=web\n  ports:\n  - port: 80              # service listens on 80\n    targetPort: 80        # forwards to pod port 80\nNow you can connect to web-service:80 or web-service.default.svc.cluster.local:80.\n\n\nNodePort\nExposes service on each node‚Äôs IP at a static port (30000-32767).\nspec:\n  type: NodePort\n  ports:\n  - port: 80\n    targetPort: 80\n    nodePort: 30080       # accessible at &lt;any-node-ip&gt;:30080\n\n\nLoadBalancer\nCreates an external load balancer (cloud provider specific).\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 80\n    targetPort: 80\nCloud provider provisions an LB with a public IP.\nAnalogy: - ClusterIP: Internal HAProxy - NodePort: Port forwarding on every machine - LoadBalancer: Cloud LB (ELB, ALB, GCP LB)"
  },
  {
    "objectID": "kubernetes_primer.html#namespaces-virtual-clusters",
    "href": "kubernetes_primer.html#namespaces-virtual-clusters",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "6. Namespaces: Virtual Clusters",
    "text": "6. Namespaces: Virtual Clusters\nNamespaces partition a cluster into virtual clusters.\nkubectl create namespace dev\nkubectl create namespace prod\napiVersion: v1\nkind: Pod\nmetadata:\n  name: my-app\n  namespace: dev\nDefault Namespaces: - default: where your stuff goes by default - kube-system: K8s system components - kube-public: public config (rarely used) - kube-node-lease: node heartbeat data\nUse Cases: - Separate environments (dev, staging, prod) - Team isolation - Resource quotas per namespace\nDNS: Services in the same namespace: service-name. Other namespace: service-name.namespace.svc.cluster.local."
  },
  {
    "objectID": "kubernetes_primer.html#configmaps-and-secrets-configuration-management",
    "href": "kubernetes_primer.html#configmaps-and-secrets-configuration-management",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "7. ConfigMaps and Secrets: Configuration Management",
    "text": "7. ConfigMaps and Secrets: Configuration Management\n\nConfigMaps\nStore non-sensitive config data.\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: app-config\ndata:\n  DATABASE_URL: \"postgresql://dbhost:5432/mydb\"\n  LOG_LEVEL: \"info\"\nUse in Pod:\nspec:\n  containers:\n  - name: app\n    image: myapp\n    envFrom:\n    - configMapRef:\n        name: app-config\nOr mount as files:\nspec:\n  containers:\n  - name: app\n    volumeMounts:\n    - name: config\n      mountPath: /etc/config\n  volumes:\n  - name: config\n    configMap:\n      name: app-config\n\n\nSecrets\nLike ConfigMaps but for sensitive data (base64 encoded, can be encrypted at rest).\napiVersion: v1\nkind: Secret\nmetadata:\n  name: db-secret\ntype: Opaque\ndata:\n  password: bXlzZWNyZXRwYXNz    # base64: \"mysecretpass\" (example only)\nspec:\n  containers:\n  - name: app\n    env:\n    - name: DB_PASSWORD\n      valueFrom:\n        secretKeyRef:\n          name: db-secret\n          key: password\nImportant: Secrets are not encrypted by default in etcd. Use encryption at rest in production."
  },
  {
    "objectID": "kubernetes_primer.html#persistent-storage-volumes",
    "href": "kubernetes_primer.html#persistent-storage-volumes",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "8. Persistent Storage: Volumes",
    "text": "8. Persistent Storage: Volumes\nContainers are stateless by default. For data persistence:\n\nEmptyDir\nTemporary storage. Lives as long as the pod.\nspec:\n  containers:\n  - name: app\n    volumeMounts:\n    - name: cache\n      mountPath: /cache\n  volumes:\n  - name: cache\n    emptyDir: {}\n\n\nPersistentVolume (PV) and PersistentVolumeClaim (PVC)\nPersistentVolume: Actual storage (NFS, cloud disk, etc.) PersistentVolumeClaim: Request for storage\nAnalogy: PV is a physical hard drive. PVC is ‚ÄúI need 10GB of storage‚Äù.\n# PVC\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: db-storage\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n# Use in Pod\nspec:\n  containers:\n  - name: postgres\n    volumeMounts:\n    - name: data\n      mountPath: /var/lib/postgresql/data\n  volumes:\n  - name: data\n    persistentVolumeClaim:\n      claimName: db-storage\nAccess Modes: - ReadWriteOnce (RWO): One node, read-write - ReadOnlyMany (ROX): Many nodes, read-only - ReadWriteMany (RWX): Many nodes, read-write (NFS, cloud file systems)\nStorageClass: Defines storage type (SSD, HDD, etc.). Cloud providers auto-provision PVs."
  },
  {
    "objectID": "kubernetes_primer.html#ingress-https-routing",
    "href": "kubernetes_primer.html#ingress-https-routing",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "9. Ingress: HTTP(S) Routing",
    "text": "9. Ingress: HTTP(S) Routing\nService gives you L4 load balancing. Ingress gives you L7 (HTTP) routing.\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: app-ingress\nspec:\n  rules:\n  - host: myapp.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: web-service\n            port:\n              number: 80\n  - host: api.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: api-service\n            port:\n              number: 8080\nWhat it does: - Routes myapp.example.com ‚Üí web-service - Routes api.example.com ‚Üí api-service - Single entry point (load balancer)\nRequires: An Ingress Controller (nginx-ingress, traefik, HAProxy, etc.)\nAnalogy: Ingress is like nginx reverse proxy as a K8s resource."
  },
  {
    "objectID": "kubernetes_primer.html#labels-and-selectors-the-glue",
    "href": "kubernetes_primer.html#labels-and-selectors-the-glue",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "10. Labels and Selectors: The Glue",
    "text": "10. Labels and Selectors: The Glue\nLabels are key-value pairs attached to objects.\nmetadata:\n  labels:\n    app: web\n    tier: frontend\n    env: prod\nSelectors query by labels:\nkubectl get pods -l app=web\nkubectl get pods -l tier=frontend,env=prod\nServices use selectors:\nselector:\n  app: web\nWhy it matters: This is how Deployments manage Pods, Services route to Pods, etc.\nBest Practice: - app: Application name - tier: frontend, backend, database - env: dev, staging, prod - version: v1, v2"
  },
  {
    "objectID": "kubernetes_primer.html#health-checks-liveness-and-readiness-probes",
    "href": "kubernetes_primer.html#health-checks-liveness-and-readiness-probes",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "11. Health Checks: Liveness and Readiness Probes",
    "text": "11. Health Checks: Liveness and Readiness Probes\nK8s needs to know if your app is healthy.\n\nLiveness Probe\n‚ÄúIs the app alive?‚Äù If it fails, K8s restarts the container.\nspec:\n  containers:\n  - name: app\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 8080\n      initialDelaySeconds: 30\n      periodSeconds: 10\n\n\nReadiness Probe\n‚ÄúIs the app ready to serve traffic?‚Äù If it fails, K8s removes it from Service endpoints.\nspec:\n  containers:\n  - name: app\n    readinessProbe:\n      httpGet:\n        path: /ready\n        port: 8080\n      initialDelaySeconds: 5\n      periodSeconds: 5\nDifference: - Liveness: App is broken ‚Üí restart - Readiness: App is starting up / overloaded ‚Üí don‚Äôt send traffic yet\n\n\nStartup Probe\nFor slow-starting apps. Disables liveness/readiness checks until app starts.\nstartupProbe:\n  httpGet:\n    path: /healthz\n    port: 8080\n  failureThreshold: 30\n  periodSeconds: 10"
  },
  {
    "objectID": "kubernetes_primer.html#resource-requests-and-limits",
    "href": "kubernetes_primer.html#resource-requests-and-limits",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "12. Resource Requests and Limits",
    "text": "12. Resource Requests and Limits\nTell K8s how much CPU/memory your app needs.\nspec:\n  containers:\n  - name: app\n    resources:\n      requests:              # minimum guaranteed\n        memory: \"128Mi\"\n        cpu: \"250m\"          # 0.25 cores\n      limits:                # maximum allowed\n        memory: \"256Mi\"\n        cpu: \"500m\"\nRequests: Used for scheduling. K8s finds a node with enough resources. Limits: Enforced. If exceeded: - Memory: Pod is killed (OOMKilled) - CPU: Throttled\nUnits: - CPU: 1 = 1 core, 500m = 0.5 cores, 100m = 0.1 cores - Memory: 128Mi = 128 MiB, 1Gi = 1 GiB\nBest Practice: Always set requests. Set limits to prevent runaway processes."
  },
  {
    "objectID": "kubernetes_primer.html#statefulsets-for-stateful-applications",
    "href": "kubernetes_primer.html#statefulsets-for-stateful-applications",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "13. StatefulSets: For Stateful Applications",
    "text": "13. StatefulSets: For Stateful Applications\nDeployment is for stateless apps. StatefulSet is for stateful apps (databases, queues).\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: postgres\nspec:\n  serviceName: postgres\n  replicas: 3\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n    spec:\n      containers:\n      - name: postgres\n        image: postgres:14\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n    spec:\n      accessModes: [ \"ReadWriteOnce\" ]\n      resources:\n        requests:\n          storage: 10Gi\nWhat it provides: - Stable network identity: postgres-0, postgres-1, postgres-2 - Stable storage: Each pod gets its own PVC - Ordered deployment/scaling: Starts 0, then 1, then 2\nDNS: postgres-0.postgres.default.svc.cluster.local\nUse Cases: Databases, message queues, anything that needs stable identity or ordered deployment."
  },
  {
    "objectID": "kubernetes_primer.html#daemonsets-run-on-every-node",
    "href": "kubernetes_primer.html#daemonsets-run-on-every-node",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "14. DaemonSets: Run on Every Node",
    "text": "14. DaemonSets: Run on Every Node\nDaemonSet ensures a pod runs on every node (or a subset).\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: node-exporter\nspec:\n  selector:\n    matchLabels:\n      app: node-exporter\n  template:\n    metadata:\n      labels:\n        app: node-exporter\n    spec:\n      containers:\n      - name: node-exporter\n        image: prom/node-exporter\nUse Cases: - Log collectors (fluentd) - Monitoring agents (node-exporter) - Storage daemons (ceph, glusterfs) - Network plugins"
  },
  {
    "objectID": "kubernetes_primer.html#jobs-and-cronjobs-batch-processing",
    "href": "kubernetes_primer.html#jobs-and-cronjobs-batch-processing",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "15. Jobs and CronJobs: Batch Processing",
    "text": "15. Jobs and CronJobs: Batch Processing\n\nJob\nRun a task to completion.\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: batch-job\nspec:\n  template:\n    spec:\n      containers:\n      - name: worker\n        image: myworker\n        command: [\"python\", \"process.py\"]\n      restartPolicy: OnFailure\n\n\nCronJob\nRun a job on a schedule.\napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: backup\nspec:\n  schedule: \"0 2 * * *\"         # every day at 2 AM\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n          - name: backup\n            image: backup-tool\n            command: [\"backup.sh\"]\n          restartPolicy: OnFailure\nCron Syntax: Same as Unix cron (* * * * * = minute hour day month weekday)."
  },
  {
    "objectID": "kubernetes_primer.html#kubectl-your-cli-tool",
    "href": "kubernetes_primer.html#kubectl-your-cli-tool",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "16. Kubectl: Your CLI Tool",
    "text": "16. Kubectl: Your CLI Tool\n\nEssential Commands\n# Get resources\nkubectl get pods\nkubectl get services\nkubectl get deployments\nkubectl get all                # all resources\n\n# Describe (detailed info)\nkubectl describe pod my-app\n\n# Logs\nkubectl logs my-app\nkubectl logs my-app -f         # follow\nkubectl logs my-app -c container-name  # specific container\n\n# Execute commands\nkubectl exec -it my-app -- /bin/bash\nkubectl exec my-app -- curl localhost:8080\n\n# Apply configuration\nkubectl apply -f deployment.yaml\nkubectl apply -f ./manifests/  # directory\n\n# Delete\nkubectl delete pod my-app\nkubectl delete -f deployment.yaml\n\n# Port forwarding (access pod locally)\nkubectl port-forward pod/my-app 8080:80\n# now access localhost:8080\n\n# Context and namespace\nkubectl config get-contexts\nkubectl config use-context prod-cluster\nkubectl config set-context --current --namespace=dev\n\n# Scaling\nkubectl scale deployment web-app --replicas=5\n\n# Rolling update\nkubectl set image deployment/web-app nginx=nginx:1.22\nkubectl rollout status deployment/web-app\nkubectl rollout undo deployment/web-app\n\n# Debug\nkubectl get events\nkubectl top nodes              # resource usage\nkubectl top pods\n\n\nUseful Flags\n-n namespace       # specify namespace\n--all-namespaces   # all namespaces\n-o yaml            # output as YAML\n-o json            # output as JSON\n-o wide            # more columns\n-l app=web         # filter by label\n--dry-run=client -o yaml  # generate YAML without creating\n\n\nQuick YAML Generation\n# Generate deployment YAML\nkubectl create deployment web --image=nginx --dry-run=client -o yaml &gt; deployment.yaml\n\n# Generate service YAML\nkubectl expose deployment web --port=80 --dry-run=client -o yaml &gt; service.yaml"
  },
  {
    "objectID": "kubernetes_primer.html#common-patterns-and-best-practices",
    "href": "kubernetes_primer.html#common-patterns-and-best-practices",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "17. Common Patterns and Best Practices",
    "text": "17. Common Patterns and Best Practices\n\n12-Factor App Alignment\n\nConfig: Use ConfigMaps/Secrets, not hardcoded values\nLogs: Write to stdout/stderr, let K8s collect them\nProcesses: Stateless containers, state in external stores\nPort binding: Containers listen on ports, Services route to them\n\n\n\nSidecar Pattern\nHelper containers that extend main container.\nExamples: - Log shipper (fluent-bit) - Service mesh proxy (Envoy, Istio) - Secrets sync (vault-agent)\n\n\nInit Containers\nRuns before main container starts.\nspec:\n  initContainers:\n  - name: wait-for-db\n    image: busybox\n    command: ['sh', '-c', 'until nc -z db 5432; do sleep 1; done']\n  containers:\n  - name: app\n    image: myapp\n\n\nMulti-Container Pods Use Cases\n‚úÖ Good: - App + log forwarder - App + proxy (service mesh) - App + secrets fetcher\n‚ùå Bad: - Frontend + backend (use separate Deployments + Service) - Microservices in one pod (defeats the purpose)\n\n\nResource Management\n# QoS Classes (implicit from requests/limits)\n\n# Guaranteed: requests == limits\nresources:\n  requests:\n    memory: \"256Mi\"\n    cpu: \"500m\"\n  limits:\n    memory: \"256Mi\"\n    cpu: \"500m\"\n\n# Burstable: requests &lt; limits\nresources:\n  requests:\n    memory: \"128Mi\"\n    cpu: \"250m\"\n  limits:\n    memory: \"256Mi\"\n    cpu: \"500m\"\n\n# BestEffort: no requests/limits (evicted first)\n\n\nBlue-Green Deployments\n# Deploy v2 alongside v1\nkubectl apply -f deployment-v2.yaml\n\n# Switch service to v2\nkubectl patch service web-service -p '{\"spec\":{\"selector\":{\"version\":\"v2\"}}}'\n\n# Rollback if needed\nkubectl patch service web-service -p '{\"spec\":{\"selector\":{\"version\":\"v1\"}}}'\n\n\nCanary Deployments\nRun two deployments with different replica counts: - web-app-stable: 9 replicas - web-app-canary: 1 replica\nService selects both via label. 10% traffic goes to canary."
  },
  {
    "objectID": "kubernetes_primer.html#networking-deep-dive",
    "href": "kubernetes_primer.html#networking-deep-dive",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "18. Networking Deep Dive",
    "text": "18. Networking Deep Dive\n\nPod-to-Pod Communication\nEvery pod gets a unique IP. Pods can talk to each other directly (no NAT).\nNetwork Model: - All pods can communicate with all other pods without NAT - All nodes can communicate with all pods without NAT - The IP a pod sees itself as is the same IP others see it as\nImplementation: CNI plugins (Calico, Flannel, Cilium, Weave).\n\n\nService Discovery\nDNS: K8s runs CoreDNS. Every service gets a DNS entry.\n\nservice-name (same namespace)\nservice-name.namespace\nservice-name.namespace.svc.cluster.local (fully qualified)\n\nEnvironment Variables: K8s injects env vars for services (legacy, DNS preferred).\n\n\nNetwork Policies\nFirewall rules for pods.\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: deny-all\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n# Allow only frontend to talk to backend\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: backend-policy\nspec:\n  podSelector:\n    matchLabels:\n      tier: backend\n  ingress:\n  - from:\n    - podSelector:\n        matchLabels:\n          tier: frontend\n    ports:\n    - protocol: TCP\n      port: 8080\nRequires: CNI plugin that supports NetworkPolicies (Calico, Cilium)."
  },
  {
    "objectID": "kubernetes_primer.html#security-basics",
    "href": "kubernetes_primer.html#security-basics",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "19. Security Basics",
    "text": "19. Security Basics\n\nRBAC (Role-Based Access Control)\nControl who can do what.\n# Role: permissions within a namespace\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: pod-reader\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\"]\n  verbs: [\"get\", \"list\"]\n# RoleBinding: assign role to user/group/service account\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: read-pods\nsubjects:\n- kind: User\n  name: jane\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: pod-reader\n  apiGroup: rbac.authorization.k8s.io\nClusterRole and ClusterRoleBinding: Cluster-wide permissions.\n\n\nService Accounts\nIdentity for pods.\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: my-app-sa\nspec:\n  serviceAccountName: my-app-sa\n  containers:\n  - name: app\n    image: myapp\nApp can now call K8s API with that service account‚Äôs permissions.\n\n\nPod Security\nSecurity Context:\nspec:\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 1000\n    fsGroup: 2000\n  containers:\n  - name: app\n    securityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      capabilities:\n        drop:\n        - ALL\nBest Practices: - Run as non-root - Read-only root filesystem - Drop all capabilities - Use PodSecurityPolicies or PodSecurityStandards"
  },
  {
    "objectID": "kubernetes_primer.html#helm-package-manager-for-kubernetes",
    "href": "kubernetes_primer.html#helm-package-manager-for-kubernetes",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "20. Helm: Package Manager for Kubernetes",
    "text": "20. Helm: Package Manager for Kubernetes\nHelm is like apt/yum/npm for K8s. Packages are called Charts.\n\nInstall Helm Chart\n# Add repo\nhelm repo add bitnami https://charts.bitnami.com/bitnami\n\n# Search\nhelm search repo postgres\n\n# Install\nhelm install my-postgres bitnami/postgresql\n\n# List releases\nhelm list\n\n# Uninstall\nhelm uninstall my-postgres\n\n\nCustom Values\n# Override defaults\nhelm install my-postgres bitnami/postgresql \\\n  --set auth.postgresPassword=secret \\\n  --set persistence.size=20Gi\nOr use a values file:\n# values.yaml\nauth:\n  postgresPassword: secret\npersistence:\n  size: 20Gi\nhelm install my-postgres bitnami/postgresql -f values.yaml\n\n\nCreate Your Own Chart\nhelm create myapp\nCreates:\nmyapp/\n‚îú‚îÄ‚îÄ Chart.yaml          # chart metadata\n‚îú‚îÄ‚îÄ values.yaml         # default config\n‚îî‚îÄ‚îÄ templates/\n    ‚îú‚îÄ‚îÄ deployment.yaml\n    ‚îú‚îÄ‚îÄ service.yaml\n    ‚îî‚îÄ‚îÄ ...\nTemplates use Go templating:\napiVersion: v1\nkind: Service\nmetadata:\n  name: {{ .Release.Name }}-service\nspec:\n  selector:\n    app: {{ .Values.appName }}\n  ports:\n  - port: {{ .Values.servicePort }}"
  },
  {
    "objectID": "kubernetes_primer.html#troubleshooting-checklist",
    "href": "kubernetes_primer.html#troubleshooting-checklist",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "21. Troubleshooting Checklist",
    "text": "21. Troubleshooting Checklist\n\nPod Not Starting\n# Check pod status\nkubectl get pod my-app\nkubectl describe pod my-app\n\n# Common issues:\n# - ImagePullBackOff: wrong image name, no access\n# - CrashLoopBackOff: app crashes on start\n# - Pending: not enough resources, no matching node\n\n\nCheck Logs\nkubectl logs my-app\nkubectl logs my-app --previous  # previous instance\n\n\nEvents\nkubectl get events --sort-by='.lastTimestamp'\nkubectl describe pod my-app  # events at the bottom\n\n\nResource Issues\nkubectl top nodes\nkubectl top pods\nkubectl describe node node-1  # see allocatable resources\n\n\nNetwork Issues\n# Test DNS\nkubectl run -it --rm debug --image=busybox --restart=Never -- nslookup web-service\n\n# Test connectivity\nkubectl run -it --rm debug --image=curlimages/curl --restart=Never -- curl http://web-service\n\n# Check service endpoints\nkubectl get endpoints web-service\n\n\nDebug Container\nkubectl debug -it my-app --image=busybox --target=my-app"
  },
  {
    "objectID": "kubernetes_primer.html#production-readiness-checklist",
    "href": "kubernetes_primer.html#production-readiness-checklist",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "22. Production Readiness Checklist",
    "text": "22. Production Readiness Checklist\n‚úÖ Deployments: - Health checks (liveness, readiness) - Resource requests and limits - Multiple replicas (3+) - Pod disruption budgets\n‚úÖ Configuration: - ConfigMaps for config - Secrets for sensitive data - External secret management (Vault, AWS Secrets Manager)\n‚úÖ Networking: - Services for stable endpoints - Ingress for HTTP routing - Network policies for security\n‚úÖ Storage: - PersistentVolumes for stateful apps - Backup strategy\n‚úÖ Monitoring: - Prometheus for metrics - Grafana for dashboards - Alertmanager for alerts - Logging (ELK, Loki, Cloud logging)\n‚úÖ Security: - RBAC configured - Service accounts with least privilege - Pod security contexts - Network policies - Secret encryption at rest\n‚úÖ Disaster Recovery: - etcd backups - Application data backups - Multi-zone/multi-region setup"
  },
  {
    "objectID": "kubernetes_primer.html#key-takeaways",
    "href": "kubernetes_primer.html#key-takeaways",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "23. Key Takeaways",
    "text": "23. Key Takeaways\n\nDeclarative, not Imperative: You declare desired state (YAML), K8s makes it happen.\nReconciliation Loop: Controllers constantly watch actual vs desired state and reconcile.\nPods are Ephemeral: Don‚Äôt rely on pod identity. Use Services, StatefulSets, or external storage.\nLabels are Everything: They connect Services to Pods, Deployments to Pods, etc.\nStart Simple: Pod ‚Üí Deployment ‚Üí Service ‚Üí Ingress. Don‚Äôt jump to complex patterns.\nUse Higher-Level Abstractions: Use Deployments, not bare Pods. Use StatefulSets for stateful apps.\nHealth Checks are Critical: Without them, K8s doesn‚Äôt know if your app is healthy.\nResource Limits Matter: Prevents noisy neighbors, enables better scheduling.\nConfigMaps/Secrets: Separate config from code.\nHelm: Don‚Äôt reinvent the wheel. Use existing charts."
  },
  {
    "objectID": "kubernetes_primer.html#next-steps",
    "href": "kubernetes_primer.html#next-steps",
    "title": "Kubernetes Primer: Container Orchestration Essentials",
    "section": "24. Next Steps",
    "text": "24. Next Steps\nAfter This Primer: - Hands-on: Deploy a real app (try a 3-tier app: frontend, backend, database) - Networking: Deep dive into Ingress controllers, service mesh (Istio, Linkerd) - Observability: Prometheus, Grafana, Jaeger, OpenTelemetry - GitOps: ArgoCD, Flux (deploy from Git, not kubectl) - Advanced Scheduling: Taints, tolerations, node affinity, pod affinity - Operators: Custom resources and controllers (Operator SDK) - Multi-tenancy: Advanced RBAC, resource quotas, pod security\nResources: - Official docs: https://kubernetes.io/docs/ - Interactive tutorial: https://kubernetes.io/docs/tutorials/kubernetes-basics/ - kubectl cheat sheet: https://kubernetes.io/docs/reference/kubectl/cheatsheet/\n\nYou now know ~80% of Kubernetes. The rest is practice, debugging, and learning from production incidents. Good luck! üöÄ"
  }
]